---
title: 图表征学习 & 扩散模型
description: 昨夜星辰昨夜风, 画楼西畔桂堂东. 身无彩凤双飞翼, 心有灵犀一点通.
date: 2023-08-04
---

- [图表征学习](https://book.douban.com/subject/36477924/)
  - 干货不多, 勉强算个入门书籍~

### 图嵌入

- 若游走中的边不存在重复, 则该游走也称为`迹`;
  此外, 若游走中的节点和边均不存在重复,
  则该游走称为一条`路径`.

```
DeepWalk 的核心思想是通过类比图上的随机游走和自然语言, 即每个节点相当于一个单词,
并将图中每个采样得到的游走视为自然语言中的一个句子.
DeepWalk 作者发现, 短距离随机游走中节点的概率分布与自然语言中的单词概率分布十分相似.
基于这一观察, DeepWalk 提出借鉴自然语言处理的单词嵌入来学习图的节点嵌入.
具体来说, DeepWalk 采用单词嵌入的 SkipGram 模型.
```

- 具体来说, Node2vec 采用的有偏随机游走为一个二阶马尔可夫过程,
  即随机游走的下一个节点概率取决于之前的两个节点.
  - 总而言之, 通过调整 `p` 和 `q` 的取值,
    Node2vec 可以获得不同特性的有偏随机游走,
    因此更具有灵活性.

```
由于 AROPE 仅需要在原始的稀疏邻接矩阵 A 上计算一次特征分解,
其时间复杂度与图规模呈线性关系, 可以扩展到大规模图. 此外,
在保持不同阶邻近度时, AROPE
仅需计算对应的变换而无须重新计算特征值分解或奇异值分解,
因此该算法可以在不同阶邻近度间快速切换,
以支持高效并有效地保持不同阶邻近度.
```

```
因此, 基于随机游走的图嵌入方法等价为构造特殊的相似度矩阵并计算矩阵分解.
一方面由于随机游走过程不需要显式地构造相似度并计算其矩阵分解,
因此随机游走方法的计算效率往往较高; 另一方面,
由于现实中随机游走的数量是有限的,
因此随机游走方法相当于在优化过程中进行了近似,
而直接采用矩阵分解方法可以更有效地优化目标函数.
```

------------------

- [深度生成模型](https://book.douban.com/subject/36503836/)

------------------

- [扩散模型](https://book.douban.com/subject/36489324/)
  - 比下面那本同名书籍好一些

```
具体来说, VAE 通过在潜在变量空间中引入一个先验分布来确保模型可以生成具有多样性的样本.
这个先验分布通常是高斯分布或者混合高斯分布. 在训练过程中,
VAE 尝试最大化重建数据的对数似然, 同时最小化模型学习到的潜在变量与先验分布之间的差异.
这个差异可以使用 KL 散度来度量, KL 散度是一种用于衡量两个分布之间差异的度量.
```

```
Transformer 模型 (2018年):
它使用自注意力机制来捕捉输入序列中不同位置之间的依赖关系, 从而更好地处理长文本序列.
Transformer 模型在机器翻译和文本生成等任务中取得了非常好的效果, 是预训练技术的一个重要里程碑.

大规模预训练模型 (2018 年至今):
例如, BERT, GPT 等. 这些模型使用更大规模的数据集进行训练,
并且使用更复杂的网络结构和训练策略来提高效果和泛化能力.
这些大规模预训练模型在自然语言处理领域取得了非常显著的成果,
并且成为当前自然语言处理研究的一个重要方向.
```

------------------

- [扩散模型](https://book.douban.com/subject/36482946/)
  - 一般般

------------------

- [这就是 ChatGPT](https://book.douban.com/subject/36449803/)
  - 一般般
