---
title: 深度学习 (中)
description: 塞下秋来风景异, 衡阳雁去无留意. 四面边声连角起, 千嶂里, 长烟落日孤城闭.
date: 2022-11-01
---

- [深度学习](https://book.douban.com/subject/27087503/)

## 卷积网络

```
卷积是一种特殊的线性运算.
卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络.
```

> ML 中的卷积运算和数学意义上的卷积有差异~

```
卷积运算可交换性的出现是因为我们将核相对输入进行了翻转,
从 m 增大的角度来看, 输入的索引在增大, 但是核的索引在减小.
我们将核翻转的唯一目的是实现可交换性. 尽管可交换性在证明时很有用,
但在神经网络的应用中却不是一个重要的性质. 与之不同的是,
许多神经网络库会实现一个相关的函数, 称为互相关函数,
和卷积运算几乎一样但是并没有对核进行翻转.

许多机器学习的库实现的是互相关函数但是称之为卷积.
在这本书中我们遵循把两种运算都叫作卷积的这个传统,
在与核翻转有关的上下文中, 我们会特别指明是否对核进行了翻转.
```

```
在机器学习中, 学习算法会在核合适的位置学得恰当的值,
所以一个基于核翻转的卷积运算的学习算法所学得的核,
是对未进行翻转的算法学得的核的翻转.
单独使用卷积运算在机器学习中是很少见的, 卷积经常与其他的函数一起使用,
无论卷积运算是否对它的核进行了翻转, 这些函数的组合通常是不可交换的.
```

```
处于卷积网络更深的层中的单元, 它们的接受域要比处在浅层的单元的接受域更大.
如果网络还包含类似步幅卷积或者池化之类的结构特征, 这种效应会加强.
这意味着在卷积网络中尽管直接连接都是很稀疏的,
但处在更深的层中的单元可以间接地连接到全部或者大部分输入图像.
```

```
池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出.
例如, 最大池化函数给出相邻矩形区域内的最大值.
其他常用的池化函数包括相邻矩形区域内的平均值,
L2 范数以及基于距中心像素距离的加权平均函数.
```

```
使用池化可以看作增加了一个无限强的先验:
这一层学得的函数必须具有对少量平移的不变性.
当这个假设成立时, 池化可以极大地提高网络的统计效率.
对空间区域进行池化产生了平移不变性,
但当我们对分离参数的卷积的输出进行池化时,
特征能够学得应该对于哪种变换具有不变性.
```

```
我们可以把卷积网络类比成全连接网络, 但对于这个全连接网络的权重有一个无限强的先验.
这个无限强的先验是说一个隐藏单元的权重必须和它邻居的权重相同, 但可以在空间上移动.
这个先验也要求除了那些处在隐藏单元的小的空间连续的接受域内的权重以外,
其余的权重都为零.
总之, 我们可以把卷积的使用当作对网络中一层的参数引入了一个无限强的先验概率分布.
这个先验说明了该层应该学得的函数只包含局部连接关系并且对平移具有等变性.
类似地, 使用池化也是一个无限强的先验: 每一个单元都具有对少量平移的不变性.
```

## 序列建模: 循环和递归网络

## 实践方法论

## 线性因子模型

## 自编码器
