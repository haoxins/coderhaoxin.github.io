---
title: 深度强化学习 (上)
description: 吹箫凌极浦, 日暮送夫君. 湖上一回首, 山青卷白云.
date: 2023-01-05
---

- [深度强化学习](https://book.douban.com/subject/36161659/)

- 随机性有两个来源: 动作和状态.
  动作的随机性来源于策略, 状态的随机性来源于状态转移.
  策略由策略函数决定, 状态转移由状态转移函数决定.
  - 本书中用
    $$ S_t $$
    和
    $$ s_t $$
    分别表示 `t` 时刻的状态及其观测值, 用
    $$ A_t $$
    和
    $$ a_t $$
    分别表示 `t` 时刻的动作及其观测值.

- `t` 时刻的动作价值函数
  $$ Q_{\pi} (s_t, a_t) $$
  依赖于以下三个因素.
  - 第一, 当前状态
    $$ s_t $$.
    当前状态越好,
    $$ Q_{\pi} (s_t, a_t) $$
    越大, 也就是说回报的期望值越大.
  - 第二, 当前动作
    $$ a_t $$.
    智能体执行的动作越好,
    $$ Q_{\pi} (s_t, a_t) $$
    越大.
  - 第三, 策略函数
    $$ \pi $$.
    策略决定未来的动作
    $$ A_{t+1} $$,
    $$ A_{t+2} $$,
    ...,
    $$ A_n $$
    的好坏: 策略越好,
    $$ Q_{\pi} (s_t, a_t) $$
    越大.

## DQN 与 Q 学习

## SARSA 算法

## 价值学习高级技巧

## 策略梯度方法

## 带基线的策略梯度方法

## 策略学习高级技巧

## 连续控制

## 对状态的不完全观测
