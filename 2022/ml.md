---
title: 机器学习 - 西瓜, 南瓜
description: 晚年惟好静, 万事不关心. 自顾无长策, 空知返旧林.
date: 2022-07-31
---

- [机器学习](https://book.douban.com/subject/26708119/)
- [机器学习公式详解](https://book.douban.com/subject/35381195/)

- 任意实矩阵
  $$ A \in \mathbb{R}^{m \times n} $$
  都可分解为
  - $$ A = U \Sigma V^{T} $$,
    (`A.33`)
  - 其中,
    $$ U \in \mathbb{R}^{m \times m} $$
    是满足
    $$ U^{T} U = I $$
    的 `m` 阶酉矩阵;
  - $$ V \in \mathbb{R}^{n \times n} $$
    是满足
    $$ V^{T} V = I $$
    的 `n` 阶酉矩阵;
  - $$ \Sigma \in \mathbb{R}^{m \times n} $$
    是
    $$ m \times n $$
    的矩阵,
  - 其中
    $$ (\Sigma)_{ii} = \sigma_{i} $$
    且其他位置的元素均为 `0`,
    $$ \sigma_{i} $$
    为非负实数且满足
    $$ \sigma_1 \ge \sigma_2 \ge ... \ge 0 $$.
- 式 (`A.33`) 中的分解称为奇异值分解 (简称 `SVD`), 其中 `U` 的列向量
  $$ u_{i} \in \mathbb{R}^{m} $$
  称为 `A` 的左奇异向量, `V` 的列向量
  $$ v_{i} \in \mathbb{R}^{n} $$
  称为 `A` 的右奇异向量,
  $$ \sigma_{i} $$
  称为奇异值.
  - 矩阵 `A` 的秩 (`rank`) 就等于非零奇异值的个数.

## 模型评估与选择

```
也就是说, 泛化误差可分解为偏差, 方差与噪声之和.
回顾偏差, 方差, 噪声的含义:
偏差度量了学习算法的期望预测与真实结果的偏离程度,
即刻画了学习算法本身的拟合能力;
方差度量了同样大小的训练集的变动所导致的学习性能的变化,
即刻画了数据扰动所造成的影响;
噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界,
即刻画了学习问题本身的难度.

偏差-方差分解说明, 泛化性能是由学习算法的能力,
数据的充分性以及学习任务本身的难度所共同决定的.
给定学习任务, 为了取得好的泛化性能, 则需使偏差较小,
即能够充分拟合数据, 并且使方差较小, 即使得数据扰动产生的影响小.

一般来说, 偏差与方差是有冲突的, 这称为偏差-方差窘境.
给定学习任务, 假定我们能控制学习算法的训练程度,
则在训练不足时, 学习器的拟合能力不够强,
训练数据的扰动不足以使学习器产生显著变化,
此时偏差主导了泛化错误率; 随着训练程度的加深,
学习器的拟合能力逐渐增强, 训练数据发生的扰动渐渐能被学习器学到,
方差逐渐主导了泛化错误率; 在训练程度充足后,
学习器的拟合能力已非常强, 训练数据发生的轻微扰动都会导致学习器发生显著变化,
若训练数据自身的, 非全局的特性被学习器学到了, 则将发生过拟合.
```

## 支持向量机

## 贝叶斯分类器

## 集成学习

## 聚类

## 降维与度量学习

## 特征选择与稀疏学习

## 计算学习理论

## 半监督学习

## 概率图模型

## 规则学习

## 强化学习
