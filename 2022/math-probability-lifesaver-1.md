---
title: 普林斯顿概率论读本 (上)
description: 翠叶藏莺, 珠帘隔燕. 炉香静逐游丝转. 一场愁梦酒醒时, 斜阳却照深深院.
date: 2022-11-24
---

- [普林斯顿概率论读本](https://book.douban.com/subject/35193606/)

> 注意, 本书中用
  $$ \log x $$
  表示以 `e` 为底 `x` 的对数, 而不是用
  $$ \ln x $$.

- 当 `x` 取值较小时, `log(1 - x)` 近似于 `-x`.
  - 在讨论中心极限定理的证明时, 我们还会遇到这种展开式.

```
关于和与积分之间的相互转化, 我们有一套庞大的理论.
你可能还记得像黎曼和, 黎曼积分这样的名词.
但要注意, 在乘积里并没有类似的概念. 我们所熟知的只有和.
虽然我们对于乘积了解得并不多, 但会看到对数可以把乘积转化成和,
这样就能进入熟悉的领域. 如果你不清楚对数为什么有用,
那现在是时候来了解它了. 对数法则是标准化测试的内容,
所以我们在这里不展开讨论. 实际上, 对数法则是解决很多问题的好方法.
```

- __几何级数公式__:
  - 设 `r` 是一个绝对值小于 `1` 的实数, 那么
  - $$ \sum_{n = 0}^{\infty} r^n = 1 + r + r^2 + r^3 + ... = \frac{1}{1 - r} $$

## 基本概率定律

```
从罗素悖论中可以推出一个结论,
那就是我们无法通过简单地收集具有给定性质的所有对象来形成集合.
幸运的是, 我们在概率论中遇到的绝大多数集合都没有这个问题,
但重要的是意识到潜在的危险, 并且要正确, 认真地理解证明.
```

- $$ A \times B $$:
  称为 `A` 和 `B` 的`笛卡儿乘积`.
  它是全体有序对 `(a, b)` 的集合, 其中
  $$ a \in A $$
  且
  $$ b \in B $$.
  - 当 `A = B` 时, 我们通常用
    $$ A^2 $$
    来表示
    $$ A \times A $$.
  - 更一般地, 如果有 `n` 个 `A` 相乘, 则记作
    $$ A^n $$.
- $$ \mathcal{P} (A) $$:
  称作 `A` 的幂集. 它是 `A` 的所有子集的集合.
  如果 `A = {x, y}`, 那么

$$
\mathcal{P} (A) =
  \left \{
    \varnothing,
    \left \{ x \right \},
    \left \{ y \right \},
    A
  \right \}
$$.

> 注意,
  $$ \mathcal{P} (A) $$
  中的元素自身就是集合.

```
一个有趣的问题是怎样以严格的, 集合论的方式来构造整数集
(或者更一般地构造实数集). 令人惊奇的是,
在只有一个空集的前提下就可以实现这一点!
我们可以利用空集 ø 来构造一个集合, 即 {ø} (包含空集的集合).
按照这种方法, 我们还能构造出 {ø, {ø}},
继续进行下去又得到了 {∅, {ø}, {ø, {ø}}}.
如果让 ø 对应于 0, {ø} 对应于 1, {ø, {ø}} 对应于 2, 等等,
那么不难看出, 每个"数"都是比它大的那个数的真子集
(因此, 集合的包含关系相当于"小于").
```

- 概率空间的有用规则: 设
  $$ (\Omega, \sum, Prob) $$
  是一个概率空间, 那么可以得到如下结论.
  - (1) __全概率公式__: 如果
    $$ A \in \sum $$,
    那么
    $$ Pr(A) + Pr(A^c) = 1 $$.
  - 也就是说,
    $$ Pr(A) = 1 - Pr(A^c) $$.
  - (2)
    $$ Pr(A \cup B) = Pr(A) + Pr(B) - Pr(A \cap B) $$.
  - 这个式子可以进一步推广. 例如, 如果有三个事件, 那么
  - $$ Pr(A_1 \cup A_2 \cup A_3) =
       Pr(A_1) + Pr(A_2) + Pr(A_3) -
       Pr(A_1 \cap A_2) - Pr(A_1 \cap A_3)- Pr(A_2 \cap A_3) +
       Pr(A_1 \cap A_2 \cap A_3) $$.
  - 这也被称为`容斥原理`.
  - (3) 如果
    $$ A \subset B $$,
    那么
    $$ Pr(A) \leqslant Pr(B) $$.
    然而, 如果 `A` 是 `B` 的真子集, 那么不一定有
    $$ Pr(A) < Pr(B) $$,
    但我们确定有
    $$ Pr(B) = Pr(A) + Pr(B \cap A^c) $$,
    其中
    $$ B \cap A^c $$
    指的是 `B` 中不属于 `A` 的所有元素.
  - (4) 如果对于任意的
    $$ i $$,
    均有
    $$ A_i \subset B $$,
    那么
    $$Pr(\cup_i A_i) \leqslant Pr(B) $$.

## 条件概率, 独立性和贝叶斯定理

- __条件概率__: 设 `B` 是满足条件
  $$ Pr(B) > 0 $$
  的事件. 那么已知 `B` 时 `A` 的条件概率就等于
  - $$ Pr(A \mid B) = Pr(A \cap B) / Pr(B) $$.

- __一般乘法法则__: 我们有
  - $$ Pr(A \cap B) = Pr(A \mid B)·Pr(B) $$.

- __独立性 (两个事件)__: 如果事件 `A` 和 `B` 满足
  - $$ Pr(A \cap B) = Pr(A)·Pr(B) $$,
  - 那么 `A` 和 `B` 就是独立的.

- __独立性 (三个事件)__: 如果事件 `A`, `B` 和 `C` 满足
  - (1)
    $$ Pr(A \cap B \cap C) = Pr(A)·Pr(B)·Pr(C) $$,
    并且
  - (2) 其中任意两个事件都是独立的,
  - 那么 `A`, `B` 和 `C` 就是相互独立的.

- __独立性 (一般情形)__: 如果事件
  $$ A_1, ..., A_n $$
  满足
  - (1)
    $$ Pr(A_1 \cap ... \cap A_n) = Pr(A_1) ... Pr(A_n) $$,
    并且
  - (2)
    $$ \left \{ A_1, ..., A_n \right \} $$
    的任意一个非空子集都是相互独立的,
  - 那么
    $$ A_1, ..., A_n $$
    就是相互独立的.

> 关于三个或更多个事件的独立性, 这里有个重要的警告:
  当任意两个事件都独立时, 三个或更多事件可能会相互依赖.

---

- __贝叶斯定理__: 由一般乘法法则可以推出:
  对于事件 `A` 和 `B`, 有
  - $$ Pr(B \mid A)·Pr(A) = Pr(A \mid B)·Pr(B) $$.
  - 因此, 只要
    $$ Pr(B) ≠ 0 $$,
    我们就有
  - $$ Pr(A \mid B) = Pr(B \mid A)·\frac{Pr(A)}{Pr(B)} $$.

- __划分成两部分__: 设 `B` 是满足
  $$ 0 < Pr(B) < 1 $$
  的事件 (那么对于事件
  $$ B^c $$,
  即 `B` 不发生, 也是如此).
  - 于是, 我们可以将事件 `A` 划分成两个互不相交的事件, 即
    $$ A \cap B $$
    和
    $$ A \cap B^c $$,
    而且有
  - $$ Pr(A) = Pr(A \mid B) Pr(B) + Pr(A \mid B^c) Pr(B^c) $$.
- 这个公式是很合理的. 通过大声朗读这个式子, 我们看到,
  `A` 发生的概率就是 (已知 `B` 发生时 `A` 发生的概率) 乘以
  (`B` 发生的概率), 然后再加上 (已知 `B` 不发生时 `A` 发生的概率)
  乘以 (`B` 不发生的概率).
  - 我们分成了两种情况: `B` 发生时的结果, 和 `B` 不发生时的结果.

```
遗憾的是, 贝叶斯定理很难应用于实际情况. 我们需要明确地知道 Pr(A) 和 Pr(B) 是多少.
通常, 虽然无法确切地知道 Pr(B) 和 Pr(A) 都是什么, 但我们会得到一些条件概率,
由此可以计算出 Pr(B) 或 Pr(A). 利用这种方法, 我们可以构造一般版本的贝叶斯定理.
但是, 为了做到这一点, 必须先提高对划分理论的认识.
```

- 在开始之前, 我们先了解一些术语. 记住, 如果集合 `A` 和集合 `B` 满足
  $$ A \cap B = \varnothing $$,
  那么它们就是不相交的.
  - 也就是说, 如果 `A` 和 `B` 没有相同的元素, 那么它们就不相交.
- 样本空间 `S` 的一个划分就是满足下列条件的可数个集合
  $$ \left \{ A_1, A_2, ... \right \} $$.
  - (1) 如果
    $$ i ≠ j $$,
    那么
    $$ A_i $$
    和
    $$ A_j $$
    不相交. 我们通常用
    $$ A_i \cap A_j = \varnothing $$
    来表示这两个集合的交是空集.
  - (2) 全体
    $$ A_i $$
    的并就是整个样本空间:
    $$ \cup_i A_i = S $$.

---

- __全概率法则__: 如果
  $$ \left \{ B_1, B_2, ... \right \} $$
  构成了样本空间 `S` 的一个划分 (分成了至多可数个部分), 那么对于任意的
  $$ A \subset S $$,
  我们有
  - $$ Pr(A) = \sum_{n} Pr(A \mid B_n)·Pr(B_n) $$.
- 对于所有的 `n`, 都应该有
  $$ 0 < Pr(B_n) < 1 $$,
  否则条件概率就是无定义的.
  - 注意, 如果有一个
    $$ B_n $$
    的概率为 `0`, 那么我们就不需要这个
    $$ B_n $$
    了, 因为它会给出因子
    $$ Pr(B_n) = 0 $$;
    但如果它的概率是 `1`, 那么其他所有项都是不必要的.

---

- __贝叶斯定理__: 设
  $$ \left \{ A_i \right \}_{i=1}^n $$
  是样本空间的一个划分, 那么
  - $$
      Pr(A \mid B) = \frac
      {Pr(B \mid A)·Pr(A)}
      {\sum_{i=1}^{n}Pr(B \mid A_i)·Pr(A_i)}
    $$.
  - 通常情况下, `A` 就是某个
    $$ A_i $$.

## 计数 II: 容斥原理

- __对立事件__: 在很多问题中, 要想求出 `A` 的概率,
  最简单的方法就是求出 `A` 不发生的概率, 因为
  $$ Pr(A) = 1 - Pr(A^c) $$.
  - 这在解决`"至少一个"`的问题上是非常有用的,
    因为它的对立事件就是什么都没有发生.

---

- 我们可以写得简洁一些. 设
  $$ A_{l_1 l_2 ... l_k} = A_{l_1} \cap A_{l_2} \cap ... \cap A_{l_k} $$
  (因此
  $$ A_{12} = A_1 \cap A_2 $$
  且
  $$ A_{489} = A_4 \cap A_8 \cap A_9 $$
  ), 于是

$$
\begin{align}
  \mid \cup_{i=1}^{n} A_i \mid
  & = \sum_{i=1}^{n} \mid A_i \mid                   \\
  & - \sum_{1 \le i < j \le n} \mid A_{ij} \mid      \\
  & + \sum_{1 \le i < j < k \le n} \mid A_{ijk} \mid \\
  & - ...                                            \\
  & + (-1)^{n-2}
      \sum_{1 \le l_1 < l_2 < ... < l_{n-1} \le n}
      \mid A_{l_1 l_2 ... l_{n-1}} \mid              \\
  & + (-1)^{n-1} \mid A_{1 2 ... n} \mid             \\
\end{align}
$$.

- 如果
  $$ A_i $$
  均为有限集, 并且我们使用的计数度量以结果空间中每个元素都是等可能的为基础,
  那么可以把上面所有的 `|S|` 都替换成 `Pr(S)`.

---

- __等可能集合的容斥原理__: 在涉及容斥原理的很多问题中, 所有集合
  $$ A_i $$
  都具有相同的大小, 所有集合
  $$ A_i \cap A_j = A_{ij} $$
  也具有相同的大小, 而且所有集合
  $$ A_i \cap A_j \cap A_k = A_{ijk} $$
  同样具有相同的大小, 等等.
  - 这使得计数更加简单, 于是公式被简化成了

$$
\begin{align}
  \mid \cup_{i=1}^{n} A_i \mid
    & = n \mid A_1 \mid                 \\
    & - \tbinom{n}{2} \mid A_{12} \mid  \\
    & + \tbinom{n}{3} \mid A_{123} \mid \\
    & - ...                             \\
    & + (-1)^{n-1} \mid A_{1 2 ... n} \mid
\end{align}
$$.

---

- 我们对容斥原理的证明是以二项式定理为基础的, 也就是
  - $$
      (x + y)^n =
      \sum_{k = 0}^{n}
      \binom{n}{k}
      x^{k}y^{n - k}
    $$;

---

- 从`"至少"`到`"恰好"`的方法:
  $$ N(K) $$
  表示至少有 `k` 个事件发生的方法数;
  $$ E(k) $$
  表示恰好有 `k` 个事件发生的方法数.
  - 那么
    $$ E(k) = N(k) - N(k + 1) $$.
  - 等价说法是,
  - $$ Pr(恰好有 k 个发生) = Pr(至少有 k 个发生) - Pr(至少有 k + 1 个发生) $$.

---

- __多项式系数__: 设 `N` 是一个正整数, 且
  $$ n_1 $$,
  $$ n_2 $$,
  ...,
  $$ n_k $$
  是满足和为 `N`
  $$ (n_1 + ... + n_k = N) $$
  的非负整数. 那么多项式系数就是

$$
\binom{N}{n_1, n_2, ..., n_k} =
\frac{N!}{n_{1}! n_{2}! ... n_{k}!}
$$

## 离散型随机变量

- __离散型随机变量的`概率密度`函数__: 设 `X` 是一个随机变量,
  它定义在离散的结果空间
  $$ \Omega $$
  上 (
  $$ \Omega $$
  是有限的或至多可数的).
  - 那么 `X` 的`概率密度`函数 (常记作
    $$ f_X $$
    ) 就是 `X` 取某个特定值的概率:
  - $$ f_{X} (x) = Prob (\omega \in \Omega : X(\omega) = x) $$.
- 注意, 有些教材用`概率质量`函数的说法, 而非概率密度函数.
- 概率密度函数的值总是大于或等于 `0`, 并且和始终为 `1`.

---

- __离散型随机变量的`累积分布`函数__: 设 `X` 是一个随机变量,
  它定义在一个有限的或至多可数的离散结果空间
  $$ \Omega $$
  上.
  - 回忆一下, `X` 的`概率密度`函数 (常记作
    $$ f_X $$
    ) 就是 `X` 取某个特定值的概率.
- `累积分布`函数 (常记作
  $$ F_X $$
  ) 则表示 `X` 不超过某个特定值的概率.
  - 它们分别记作
  - $$ f_{X} (x) = Prob (\omega \in \Omega : X(\omega) = x) $$
  - $$ F_{X} (x) = Prob (\omega \in \Omega : X(\omega) ≤ x) $$.

## 工具: 期望

- __泰勒级数__: 如果 `f` 是 `n` 次可微分的 (其中
  $$ f^{(k)}(x) $$
  表示 `f` 在 `x` 处的 `k` 阶导数),
  那么 `f` 在 `a` 点处的 `n` 阶泰勒级数就是

$$
T_{n} (x) := f(a) + f'(a)(x - a) +
\frac{f''(a)}{2!} (x - a)^2 + ... +
\frac{f^{(n)} (a)}{n!} (x - a)^n =
\sum_{k = 0}^{n} \frac{f^{(k)} (a)}{k!} (x - a)^k
$$.

- 我们把
  $$ f^{(k)} (a) / k! $$
  称为 `f` 关于 `a` 的第 `k` 个`泰勒系数`.
  - 在很多应用中, 我们希望得到原点处的泰勒级数, 所以 `a = 0`
    (在一些教材中, 这被称作麦克劳林级数).
- 泰勒级数给出了函数及其导数在一点处的性质,
  由此可以估算出该函数在其他点处的值.

---

- __期望值, 矩__: 设 `X` 是定义在
  $$ \mathbb{R} $$
  上的随机变量, 它的概率密度函数是
  $$ f_{X} $$.
  函数 `g(X)` 的`期望值`是:

$$
\mathbb{E} \left [ g(X) \right ] =
\begin{cases}
  \int_{- \infty}^{\infty} g(x) \cdot f_{X} (x) dx & \mbox{若 }X\mbox{ 是连续的} \\
  \sum_{n} g(x_n) \cdot f_{X} (x_n) & \mbox{若 }X\mbox{ 是离散的}
\end{cases}
$$

- 最重要的情形是
  $$ g(x) = x^r $$.
  我们把
  $$ \mathbb{E} \left [ X^r \right ] $$
  称为 `X` 的 `r` 阶`矩`, 把
  $$ \mathbb{E} \left [ ( X - \mathbb{E} \left [ X \right ] )^r \right ] $$
  称为 `X` 的 `r` 阶`中心矩`.

---

- __均值和方差__: 设 `X` 是一个连续型或离散型的随机变量,
  它的概率密度函数是
  $$ f_X $$.
  - `(1)` `X` 的均值 (即平均值或期望值) 是一阶矩.
    我们把它表示为
    $$ \mathbb{E} \left [ X \right ] $$
    或
    $$ μX $$
    (当随机变量很明确时, 通常不给出下标 `X`, 而只写 `μ`). 具体地说,
  - $$
      μ =
      \begin{cases}
        \int_{- \infty}^{\infty} x \cdot f_{X} (x) dx & \mbox{若 }X\mbox{ 是连续的} \\
        \sum_{n} x_n \cdot f_{X} (x_n) & \mbox{若 }X\mbox{ 是离散的}
      \end{cases}
    $$
  - `(2)` `X` 的方差, 记作
    $$ \sigma_{X}^2 $$
    或
    $$ Var(X) $$,
    是二阶中心距, 也可以说是
    $$ g(X) = (X - μ_{X})^2 $$
    的期望值. 同样, 当随机变量很明确时, 通常不给出下标 `X`, 而只写
    $$ \sigma^2 $$.
    把它完整地写出来, 就是
  - $$
      \sigma_{X}^2 =
      \begin{cases}
        \int_{- \infty}^{\infty} (x - μ_{X})^{2} f_{X} (x) dx & \mbox{若 }X\mbox{ 是连续的} \\
        \sum_{n} (x_{n} - μ_{X})^{2} f_{X} (x_n) & \mbox{若 }X\mbox{ 是离散的}
      \end{cases}
    $$
  - 因为
    $$ μ_{X} = \mathbb{E} \left [ X \right ] $$,
    所以在一系列代数运算后, 我们有
  - $$
      \sigma^2 =
      \mathbb{E} \left [ (X - \mathbb{E} \left [ X \right ] )^2 \right ] =
      \mathbb{E} \left [ X^2 \right ] - \mathbb{E} \left [ X \right ] ^2
    $$.
  - 这个式子把方差和 `X` 的前二阶矩联系起来, 在很多计算中都非常有用.
    标准差是方差的平方根, 即
    $$ \sigma_{X} =\sqrt{\sigma_{X}^2} $$.
  - `(3)` 技术说明: 为了保证均值存在, 我们希望
    $$ \int_{- \infty}^{\infty} \mid x \mid f_{X} (x) dx $$
    (在连续的情形下) 或
    $$ \sum_n \mid x_n \mid f_{X} (x_n) $$
    (在离散的情形下) 是有限的.

- __方差与标准差__: 与方差相比, 标准差的优势在于它和均值有相同的单位.
  - 因此, 标准差是衡量结果在均值附近波动幅度的自然尺度.

---

- __联合概率密度函数__: 设
  $$ X_1 $$,
  $$ X_2 $$,
  ...,
  $$ X_n $$
  都是连续型随机变量, 它们的概率密度函数分别是
  $$ f_{X_1} $$,
  $$ f_{X_2} $$,
  ...,
  $$ f_{X_n} $$.
- 假设每个
  $$ X_i $$
  都定义在
  $$ \mathbb{R} $$
  (实数集) 的一个子集上.
  - 那么,
    $$ (X_1, ..., X_n) $$
    的联合概率密度函数就是一个非负的可积函数
    $$ f_{X_1, ..., X_n} $$,
    满足:
  - 对于每一个恰当的集合
    $$ S \subset \mathbb{R} $$,
    均有

$$
Prob((X_1, ..., X_n) \in S) =
\int
...
\int_{S}
f_{X_1, ..., X_n} (x_1, ..., x_n) d x_{1} ... d x_{n}
$$,

- 并且

$$
f_{X_i} (x_i) =
\int_{x_1 = - \infty}^{\infty}
...
\int_{x_{i - 1} = - \infty}^{\infty}
\int_{x_{i + 1} = - \infty}^{\infty}
...
\int_{x_n = - \infty}^{\infty}
f_{X_1, ..., X_{i - 1}, X_{i + 1}, ..., X_n}
(x_1, ..., x_{i - 1}, x_{i + 1}, ..., x_n)
\prod_{j = 1, j \ne i}^{n} d x_j
$$.

- 我们把
  $$ f_{X_i} $$
  称为
  $$ X_i $$
  的`边缘概率密度函数`, 可以通过对其他 `n - 1` 个变量求积分来得到.
  - 这 `n` 个随机变量
    $$ X_1 $$,
    ...,
    $$ X_n $$
    相互独立, 当且仅当
  - $$ f_{X_1, ..., X_n} (x_1, ..., x_n) = f_{X_1}(x_1) ... f_{X_n}(x_n) $$.
  - 对于离散型随机变量, 只需要把积分替换成求和即可.
