---
title: 数据密集型应用系统设计
description: 江天一色无纤尘, 皎皎空中孤月轮. 江畔何人初见月? 江月何年初照人?
date: 2021-07-06
---

* [数据密集型应用系统设计](https://book.douban.com/subject/30329536/)
  - 原作名: **Designing Data-Intensive Applications**
  - 出版年: 2018-09-01

## 数据模型与查询语言

```
但是, 如果多对多的关系在数据中很常见呢?
关系模型能够处理简单的多对多关系,
但是随着数据之间的关联越来越复杂,
将数据建模转化为图模型会更加自然.

图由两种对象组成: 顶点 和 边 (也称为 关系)
```

> **关系**: 关联更多, 更深, 即: 更复杂

* Gremlin
  - [apache/tinkerpop](https://github.com/apache/tinkerpop)
* Cypher (Neo4j)
* SPARQL
* Datalog (Prolog 子集)

## 数据存储与检索

* **Log**: 一个仅能追加的记录序列

```
日志结构的合并树
(Log-Structured Merge-Tree, 或 LSM-Tree),
它建立在更早期的日志结构文件系统之上.
因此基于合并和压缩排序文件的存储引擎通常都被称为 LSM 存储引擎.
```

```
当查找数据库中某个不存在的键时 LSM-Tree 算法可能很慢:
在确定键不存在之前, 必须先检查内存表,
然后将段一直回溯访问到最旧的段文件
(可能必须从磁盘多次读取).
为了优化这种访问, 存储引擎通常使用额外的布隆过滤器
(布隆过滤器是内存高效的数据结构, 用于近似计算集合的内容.
如果数据库中不存在某个键, 它能够很快告诉你结果,
从而节省了很多对于不存在的键的不必要的磁盘读取)
```

* LSM-tree

```
由于数据按排序存储, 因比可以有效地执行区间查询
(从最小值到最大值扫描所有的键),
并且由于磁盘是顺序写入的,
所以 LSM-tree 可以支持非常高的写入吞吐量.
```

* 对比 B-tree 和 LSM-tree

```
根据经验, LSM-tree 通常对于写入更快,
而 B-tree 被认为对于读取更快.
读取通常在 LSM-tree 上较慢,
因为它们必须在不同的压缩阶段检查多个不同的数据结构和 SSTable.
```

## 数据编码与演化

```
向后兼容:
  较新的代码 可以读取由 旧代码 编写的数据
向前兼容:
  较旧的代码 可以读取由 新代码 编写的数据
```

* OLAP 列式存储
  - 列压缩 位图编码

```
面向列的 存储压缩 和 排序 都非常有助于加速读取.
但是, 它们的缺点是让写入更加困难.
```

* Parquet

* **数据 比 代码 更长久!**
  - 哈哈!

## 数据复制

* 基于语句的复制
  - 如果遇到语句 `UPDATE ... WHERE ... NOW()`
  - 自增列, 触发器, 存储过程, UDF

* 基于预写日志 (WAL) 传输

* 基于行的逻辑日志复制
  - 变更数据捕获 (CDC)

* [Apache CouchDB](https://github.com/apache/couchdb)
  - https://couchdb.apache.org
  - Seamless multi-master syncing database
  - with an intuitive HTTP/JSON API
  - 之前看见 CouchDB, 只注意到了 `HTTP/JSON API`
  - 今天才清晰地意识到它是 **multi-master**
  - 毕竟, 也没这个需求~

* 自动冲突解决

```
冲突解决的规则可能会变得越来越复杂, 且自定义代码很容易出错.

有一些有意思的研究尝试自动解决并发修改所引起的冲突.

1. 无冲突的复制数据类型 (Conflict-free Replicated Datatypes, CRDT)

CRDT 是可以由多个用户同时编辑的数据结构, 包括 map, ordered list, 计数器等,
并且以内置的合理方式自动地解决冲突. 一些 CRDT 已经在 Riak 2.0 中得以具体实现.

2. 可合并的持久数据结构 (Mergeable persistent data)

它跟踪变更历史, 类似于 Git 版本控制系统, 并提出三向合并功能
(three-way merge function. CRDT 采用双向合并).

3. 操作转换 (Operational transformationl)

它是 Google Docs 等协作编辑应用背后的冲突解决算法.
专为可同时编辑的有序列表而设计, 如文本文档的字符列表.

这些算法总体来讲还处于早期阶段, 但将来它们可能会被整合到更多的数据系统中.
这些自动冲突解决方案可以使 主复制模型 更简单, 更容易被应用程序集成.
```

* [Introducing Riak 2.0: Data Types, Strong Consistency, Full-Text Search](https://riak.com/introducing-riak-2-0/)
  - Posted October 29, 2013
  - https://github.com/basho
  - https://github.com/basho-labs

### 复制滞后

* Dynamo (Not DynamoDB) 风格的数据存储系统经常使用以下两种机制:

```
读修复

当客户端并行读取多个副本时, 可以检测到过期的返回值.
这种方法主要适合那些被频繁读取的场景.

反熵过程

此外, 一些数据存储有后台进程不断查找副本之间数据的差异,
将任何缺少的数据从一个副本复制到另一个副本.
与基于主节点复制的复制日志不同,
此反熵过程并不保证以特定的顺序复制写入,
并且会引入明显的同步滞后.
```

* **并发性, 时间和相对性**

```
通常如果两个操作 "同时" 发生, 则称之为并发,
然而事实上, 操作是否在时间上重叠并不重要.
由于分布式系统中复杂的时钟同步问题, 现实当中,
我们很难严格确定它们是否同时发生.
为更好地定义并发性, 我们并不依赖确切的发生时间,
即不管物理的时机如何,
如果两个操作并不需要意识到对方, 我们即可声称它们是并发操作.

一些人尝试把这个思路与物理学中狭义相对论联系起来,
后者引入了 "信息传递不能超越光速" 的假定,
如果两个事件发生的间隔短于光在它们之间的折返,
那么这两个事件不可能有相互影响, 因此就是并发.

在计算机系统中, 即使光速快到允许一个操作影响到另一个操作,
但两个操作仍可能被定义为并发.
例如, 发生了网络拥塞或中断,
可能就会出现两个操作由于网络问题导致一个操作无法感知另一个,
因此二者成为并发.
```

* 三种多副本方案

```
主从复制

所有的客户端写入操作都发送到某一个节点 (主节点),
由该节点负责将数据更改事件发送到其他副本 (从节点).
每个副本都可以接收读请求, 但内容可能是过期值.

多主节点复制

系统存在多个主节点, 每个都可以接收写请求,
客户端将写请求发送到其中的一个主节点上,
由该主节点负责将数据更改事件同步到其他主节点和自己的从节点.

无主节点复制

客户端将写请求发送到多个节点上, 读取时从多个节点上并行读取,
以此检测和纠正某些过期数据.
```

```
写后读一致性

保证用户总能看到自己所提交的最新数据.

单调读

用户在某个时间点读到数据之后,
保证此后不会出现比该时间点更早的数据.

前缀一致读

保证数据之间的因果关系, 例如, 总是以正确的顺序先读取问题, 然后看到回答.
```

## 数据分区

* 读自己的写
  - 用户 A 写入 `主`, 立即读 `从`
  - 写后读一致性/读写一致性

* 单调读

* 两种主要的分区方法

```
基于关键字区间的分区

先对关键字进行排序,
每个分区只负责一段包含最小到最大关键字范围的一段关键字.
对关键字排序的优点是可以支持高效的区间查询,
但是如果应用程序经常访问与排序一致的某段关键字,
就会存在热点的风险.
采用这种方法, 当分区太大时, 通常将其分裂为两个子区间,
从而动态地再平衡分区.

哈希分区

将哈希函数作用于每个关键字, 每个分区负责一定范围的哈希值.
这种方法打破了原关键字的顺序关系, 它的区间查询效率比较低,
但可以更均匀地分配负载. 采用哈希分区时,
通常事先创建好足够多 (但固定数量) 的分区,
让每个节点承担多个分区,
当添加或删除节点时将某些分区从一个节点迁移到另一个节点,
也可以支持动态分区.
```

```
混合上述两种基本方法也是可行的, 例如使用复合键:
键的一部分来标识分区, 而另一部分来记录排序后的顺序.
我们还讨论了分区与二级索引, 二级索引也需要进行分区,

有两种方法:

基于文档来分区二级索引 (本地索引)

二级索引存储在与关键字相同的分区中,
这意味着写入时我们只需要更新一个分区,
但缺点是读取二级索引时需要在所有分区上执行
scatter/gather.

基于词条来分区二级索引 (全局索引)

它是基于索引的值而进行的独立分区.
二级索引中的条目可能包含来自关键字的多个分区里的记录.
在写入时, 不得不更新二级索引的多个分区;
但读取时, 则可以从单个分区直接快速提取数据.
```

## 事务

### ACID

```
事务所提供的安全保证即大家所熟知的 ACID, 分别代表

原子性 (Atomicity),
一致性 (Consistency),
隔离性 (Isolation),
持久性 (Durability).

想法非常美好, 细节方见真章.
当听到一个系统声称自己 "兼容 ACID" 时,
其实你无法确信它究竟能提供了什么样的保证,
而不符合 ACID 标准的系统有时被冠以 BASE,
取另外几个特性的首字母, 即

基本可用性 (Basically Available),
软状态 (Soft state),
最终一致性 (Eventual consistency).

听下来它似乎比 ACID 更加模棱两可.
BASE 唯一可以确定的是 "它不是 ACID",
此外它几乎没有承诺任何东西.
```

* **原子性**

```
ACID 原子性 其实描述了客户端发起一个包含多个写操作的请求时可能发生的情况,
例如在完成了一部分写入之后, 系统发生了故障, 包括进程崩溃, 网络中断,
磁盘变满或者违反了某种完整性约束等; 把多个写操作纳入到一个原子事务,
万一出现了上述故障而导致没法完成最终提交时, 则事务会中止,
并且数据库须丢弃或撤销那些局部完成的更改.

假如没有原子性保证, 当多个更新操作中间发生了错误,
就需要知道哪些更改已经生效, 哪些没有生效, 这个寻找过程会非常麻烦.
或许应用程序可以重试, 但情况类似, 并且可能导致重复更新或者不正确的结果.
原子性则大大简化了这个问题: 如果事务已经中止,
应用程序可以确定没有实质发生任何更改, 所以可以安全地重试.

因此 ACID 中原子性所定义的特征是:

在出错时中止事务, 并将部分完成的写入全部丢弃.
也许可中止性比原子性更为准确.
```

* **一致性**

```
ACID 中的一致性的主要是指对数据有特定的预期状态,
任何数据更改必须满足这些状态约束 (或者恒等条件).

例如, 对于账单系统, 账户的贷款余额应和借款余额保持平衡.
如果某事务从一个有效的状态开始, 并且事务中任何更新操作都没有违背约束,
那么最后的结果依然符合有效状态.

这种一致性本质上要求应用层来维护状态一致 (或者恒等),
应用程序有责任正确地定义事务来保持一致性.
这不是数据库可以保证的事情: 即如果提供的数据修改违背了恒等条件,
数据库很难检测进而阻止该操作.

数据库可以完成针对某些特定类型的恒等约束检查,
例如使用外键约束或唯一性约束.
但通常主要靠应用程序来定义数据的有效/无效状态,
数据库主要负责存储.
```

* **隔离性**

```
ACID 语义中的 隔离性 意味着并发执行的多个事务相互隔离,
它们不能互相交叉. 经典的数据库教材把隔离定义为可串行化,
这意味着可以假装它是数据库上运行的唯一事务.
虽然实际上它们可能同时运行,
但数据库系统要确保当事务提交时,
其结果与串行执行 (一个接一个执行) 完全相同.
```

```
ACID 中的 原子性 和 隔离性
主要针对客户端在同一事务中包含多个写操作时,
数据库所提供的保证

原子性

如果一系列写操作中间发生了错误, 则事务必须中止,
并且事务中已完成的写入应该被丢弃.
换言之, 不用担心数据库的部分失败,
它总是保证要么全部成功, 要么全部失败.

隔离性

同时运行的事务不应相互干扰. 例如, 如果某个事务进行多次写入,
则另一个事务应该观察到的是其全部完成 (或者一个都没完成) 的结果,
而不应该看到中间的部分结果.
```

* **读-提交**
  - 读-提交是最基本的事务隔离级别, 它只提供以下两个保证
  - `读数据库时`, 只能看到已成功提交的数据 (防止"脏读")
  - `写数据库时`, 只会覆盖已成功提交的数据 (防止"脏写")

* 这两个保证更深入的介绍如下

```
防止脏读

假定某个事务已经完成部分数据写入, 但事务尚未提交 (或中止),
此时另一个事务是否可以看到尚未提交的数据呢?
如果是的话, 那就是脏读.

读-提交级别的事务隔离必须做到防止发生脏读.
这意味着事务的任何写入只有在成功提交之后,
才能被其他人观察到 (并且所有的写全部可见)

防止脏写

如果两个事务同时尝试更新相同的对象, 会发生什么情况呢?
我们不清楚写入的顺序, 但可以想象后写的操作会覆盖较早的写入.

但是, 如果先前的写入是尚未提交事务的一部分, 是否还是被覆盖?
如果是, 那就是脏写.

读-提交隔离级别下所提交的事务可以防止脏写,
通常的方式是推迟第二个写请求,
直到前面的事务完成提交 (或者中止).
```

* **实现快照级别隔离**

```
与读-提交隔离类似, 快照级别隔离的实现通常采用写锁来防止脏写,
这意味着正在进行写操作的事务会阻止同一对象上的其他事务.
但是, 读取则不需要加锁. 从性能角度看,
快照级别隔离的一个关键点是读操作不会阻止写操作, 反之亦然.
这使得数据库可以在处理正常写入的同时,
在一致性快照上执行长时间的只读查询,
且两者之间没有任何锁的竞争.

为了实现快照级别隔离,
考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态,
所以数据库保留了对象多个不同的提交版本,
这种技术因此也被称为多版本并发控制
(Multi-Version Concurrency Control, MVCC).

如果只是为了提供读-提交级别隔离, 而不是完整的快照级别隔离,
则只保留对象的两个版本就足够了:
一个已提交的旧版本和尚未提交的新版本.
所以, 支持快照级别隔离的存储引擎往往直接采用 MVCC 来实现读-提交隔离.
典型的做法是, 在读-提交级别下, 对每一个不同的查询单独创建一个快照;
而快照级别隔离则是使用一个快照来运行整个事务.
```

* 一致性快照的可见性规则

```
当事务读数据库时, 通过事务 ID 可以决定哪些对象可见, 哪些不可见.
要想对上层应用维护好快照的一致性, 需要精心定义数据的可见性规则.

例如:

1. 每笔事务开始时, 数据库列出所有当时尚在进行中的其他事务
   (即尚未提交或中止), 然后忽略这些事务完成的部分写入
   (尽管之后可能会被提交), 即不可见.

2. 所有中止事务所做的修改全部不可见.

3. 较晚事务 ID (即晚于当前事务) 所做的任何修改不可见,
   不管这些事务是否完成了提交.
   除此之外, 其他所有的写入都对应用查询可见.

换句话说, 仅当以下两个条件都成立, 则该数据对象对事务可见:

1. 事务开始的时刻, 创建该对象的事务已经完成了提交.
2. 对象没有被标记为删除; 或者即使标记了,
   但删除事务在当前事务开始时还没有完成提交.

长时间运行的事务可能会使用快照很长时间, 从其他事务的角度来看,
它可能在持续访问正在被覆盖或删除的内容. 由于没有就地更新,
而是每次修改总创建一个新版本,
因此数据库可以以较小的运行代价来维护一致性快照.
```

```
更新丢失可能发生在这样一个操作场景中:
应用程序从数据库读取某些值, 根据应用逻辑做出修改, 然后写回新值
(read-modify-write 过程).
当有两个事务在同样的数据对象上执行类似操作时, 由于隔离性,
第二个写操作并不包括第一个事务修改后的值,
最终会导致第一个事务的修改值可能会丢失.
这种冲突还可能在其他不同的场景下发生, 例如:

1. 递增计数器, 或更新账户余额 (需要读取当前值, 计算新值并写回更新后的值)
2. 对某复杂对象的一部分内容执行修改, 例如对 JSON 文档中一个列表添加新元素
   (需要读取并解析文档, 执行更改并写回修改后的文档)
3. 两个用户同时编辑 wiki 页面, 且每个用户都尝试将整个页面发送到服务器,
   覆盖数据库中现有内容以使更改生效.

并发写事务冲突是一个普遍问题, 目前有多种可行的解决方案.
```

* **为何产生写倾斜?**

```
上述所有写倾斜的例子都遵循以下类似的模式

1. 首先输入一些匹配条件, 即采用 SELECT 查询所有满足条件的行
2. 根据查询的结果, 应用层代码来决定下一步的操作
   (有可能继续, 或者报告错误并中止)
3. 如果应用程序决定继续执行, 它将发起数据库写入
   (INSERT, UPDATE 或 DELETE) 并提交事务

而这个写操作会改变 步骤2 做出决定的前提条件.
换句话说, 如果提交写入之后再重复执行 步骤1 的 SELECT 查询,
就会返回完全不同的结果, 原因是刚刚的写操作改变了决定的前提条件.
```

```
这种在一个事务中的写入改变了另一个事务查询结果的现象,
称为幻读.
快照级别隔离可以避免只读查询时的幻读,
但是对于我们上面所讨论那些 读-写 事务,
它却无法解决棘手的写倾斜问题.
```

```
隔离级别通常难以理解, 而且不同的数据库的实现不尽一致
(例如 "可重复读取" 的含义在各家数据库的差别很大).

如果去检查应用层的代码, 往往很难判断它在特定的隔离级别下是否安全,
特别是对于大型应用系统, 几乎无法预测所有可能并发情况.

同时, 还缺乏好的工具来帮助检测竞争状况. 理论上, 静态分析可能有所帮助,
但更多的还只是学术研究, 缺乏实用性.
测试并发性问题往往效率很低, 一切取决于时机,
它只有在特定的情景下才会出现, 存在很大的不确定性.

可串行化隔离通常被认为是最强的隔离级别.
它保证即使事务可能会并行执行,
但最终的结果与每次一个即串行执行结果相同.
这意味着, 如果事务在单独运行时表现正确,
那么它们在并发运行时结果仍然正确,
换句话说, 数据库可以防止所有可能的竞争条件.
```

```
如果串行化隔离比其他各种弱隔离级别好得多,
那么为什么没有广泛使用呢?
要回答这个问题, 我们需要看看可串行化究竟是什么, 以及如何执行.

目前大多数提供可串行化的数据库都使用了以下三种技术之一:

1. 严格按照串行顺序执行
2. 两阶段锁定, 几十年来这几乎是唯一可行的选择
3. 乐观并发控制技术
```

* **串行执行小结**

```
当满足以下约束条件时, 串行执行事务可以实现串行化隔离:

事务必须简短而高效, 否则一个缓慢的事务会影响到所有其他事务的执行性能.

仅限于活动数据集完全可以加载到内存的场景.
有些很少访问的数据可能会被移到磁盘,
但万一单线程事务需要访问它, 就会严重拖累性能.

写入吞吐量必须足够低, 才能在单个 CPU 核上处理;
否则就需要采用分区, 最好没有跨分区事务.

跨分区事务虽然也可以支持, 但是占比必须很小.
```

* **两阶段加锁**

```
近三十年来, 可以说数据库只有一种被广泛使用的串行化算法,
那就是两阶段加锁 (two-phase locking, 2PL).

2PL 不是 2PC

虽然两阶段加锁 (2PL) 听起来和两阶段提交 (two-phase commit, 2PC) 很相近,
但它们是完全不同的东西.
```

* **实现两阶段加锁**

```
目前, 2PL 已经用于 MySQL (InnoDB).

此时数据库的每个对象都有一个读写锁来隔离读写操作.
即锁可以处于共享模式或独占模式. 基本用法如下:

如果事务要读取对象, 必须先以共享模式获得锁.
可以有多个事务同时获得一个对象的共享锁,
但是如果某个事务已经获得了对象的独占锁,
则所有其他事务必须等待.

如果事务要修改对象, 必须以独占模式获取锁.
不允许多个事务同时持有该锁 (包括共享或独占模式),
换言之, 如果对象上已被加锁, 则修改事务必须等待.
如果事务首先读取对象, 然后尝试写入对象,
则需要将共享锁升级为独占锁.
升级锁的流程等价于直接获得独占锁.

事务获得锁之后, 一直持有锁直到事务结束 (包括提交或中止).
这也是名字 "两阶段" 的来由,
在第一阶段即事务执行之前要获取锁,
第二阶段 (即事务结束时) 则释放锁.

由于使用了这么多的锁机制, 所以很容易出现死锁现象,
例如 事务A 可能在等待 事务B 释放它的锁,
而 事务B 在等待 事务A 释放所持有的锁.
数据库系统会自动检测事务之间的死锁情况, 并强行中止其中的一个以打破僵局,
这样另一个可以继续向前执行.
而被中止的事务需要由应用层来重试.
```

```
一种称为 可串行化的快照隔离
(Serializable Snapshot Isolation, SSI)
算法看起来让人眼前一亮. 它提供了完整的可串行性保证,
而性能相比于快照隔离损失很小. SSI 算法于 2008 年被首次提出,
后来成为 Michael Cahill 的博士论文研究主题.

目前, SSI 可用于单节点数据库 (PostgreSQL 9.1 之后的可串行化隔离).
相比于其他并发控制机制, 它很有可能成为未来数据库的标配.
```

* **悲观与乐观的并发控制**

```
两阶段加锁是一种典型的悲观并发控制机制.
它基于这样的设计原则: 如果某些操作可能出错
(例如与其他并发事务发生了锁冲突),
那么直接放弃, 采用等待方式直到绝对安全.
这和多线程编程中互斥锁是一致的.

某种意义上讲, 串行执行是种极端悲观的选择:
事务执行期间, 等价于事务对整个数据库 (或数据库的一个分区) 持有互斥锁.
而我们只能假定事务执行得足够快, 持锁时间足够短, 来稍稍弥补这种悲观色彩.

相比之下, 可串行化的快照隔离则是一种乐观并发控制.
在这种情况下, 如果可能发生潜在冲突, 事务会继续执行而不是中止,
寄希望一切相安无事; 而当事务提交时 (只有可串行化的事务被允许提交),
数据库会检查是否确实发生了冲突 (即违反了隔离性原则),
如果是的话, 中止事务并接下来重试.
```

```
顾名思义, SSI 基于快照隔离, 也就是说,
事务中的所有读取操作都是基于数据库的一致性快照.
这是与早期的乐观并发控制主要区别. 在快照隔离的基础上,
SSI 新增加了相关算法来检测写入之间的串行化冲突从而决定中止哪些事务.

与两阶段加锁相比, 可串行化快照隔离的一大优点是
事务不需要等待其他事务所持有的锁.
这一点和快照隔离一样, 读写通常不会互相阻塞.
这样的设计使得查询延迟更加稳定, 可预测.
特别是, 在一致性快照上执行只读查询不需要任何锁,
这对于读密集的负载非常有吸引力.
与串行执行相比, 可串行化快照隔离可以突破单个 CPU 核的限制.
```

```
脏读
客户端读到了其他客户端尚未提交的写入.
读-提交以及更强的隔离级别可以防止脏读.

脏写
客户端覆盖了另一个客户端尚未提交的写入.
几乎所有的数据库实现都可以防止脏写.

读倾斜 (不可重复读)
客户在不同的时间点看到了不同值. 快照隔离是最用的防范手段,
即事务总是在某个时间点的一致性快照中读取数据.
通常采用多版本并发控制 (MVCC) 来实现快照隔离.

更新丢失
两个客户端同时执行 读-修改-写入 操作序列,
出现了其中一个覆盖了另一个的写入,
但又没有包含对方最新值的情况,
最终导致了部分修改数据发生了丢失.
快照隔离的一些实现可以自动防止这种异常,
而另一些则需要手动锁定查询结果 (SELECT FOR UPDATE).

写倾斜
事务首先查询数据, 根据返回的结果而作出某些决定, 然后修改数据库.
当事务提交时, 支持决定的前提条件已不再成立.
只有可串行化的隔离才能防止这种异常.

幻读
事务读取了某些符合查询条件的对象, 同时另一个客户端执行写入,
改变了先前的查询结果.
快照隔离可以防止简单的幻读, 但写倾斜情况则需要特殊处理,
例如采用区间范围锁.

弱隔离级别可以防止上面的某些异常,
但还需要应用开发人员手动处理其他复杂情况 (例如, 显式加锁).
只有可串行化的隔离可以防止所有这些问题.
```

* **严格串行执行事务**

```
如果每个事务的执行速度非常快且单个 CPU 核可以满足事务的吞吐量要求,
严格串行执行是一个非常简单有效的方案.
```

* **可串行化的快照隔离 (SSI)**

```
一种最新的算法, 可以避免前面方法的大部分缺点.
它秉持乐观预期的原则, 允许多个事务并发执行而不互相阻塞;
仅当事务尝试提交时, 才检查可能的冲突.
如果发现违背了串行化, 则某些事务会被中止.
```

## 分布式系统的挑战

* 三种常见的计时系统模型

```
同步模型

同步模型假定有上界的网络延迟, 有上界的进程暂停和有上界的时钟误差.
注意, 这并不意味着完全同步的时钟或者网络延迟为零.
它只意味着你清楚地了解网络延迟, 暂停和时钟漂移不会超过某个固定的上限.
大多数实际系统的实际模型并非同步模型, 因为无限延迟和暂停确实可能发生.

部分同步模型

部分同步意味着系统在大多数情况下像一个同步系统一样运行,
但有时候会超出网络延迟, 进程暂停和时钟漂移的预期上界.
这是一个比较现实的模型:
大多数情况下, 网络和进程比较稳定 (否则几乎不可能提供持续的服务),
但是我们必须考虑到任何关于时机的假设都有偶尔违背的情况,
而一旦发生, 网络延迟, 暂停和时钟偏差可能会变得非常大.

异步模型

在这个模型中, 一个算法不会对时机做任何的假设,
甚至里面根本没有时钟 (也就没有超时机制).
某些算法可以支持纯异步模型, 但并不常见.
```

* 三种最常见的节点失效系统模型

```
崩溃-中止模型

在崩溃-中止模型中, 算法假设一个节点只能以一种方式发生故障,
即遭遇系统崩溃. 这意味着节点可能在任何时候突然停止响应,
且该节点以后永远消失, 无法恢复.

崩溃-恢复模型

节点可能会在任何时候发生崩溃且可能会在一段 (未知的) 时间之后得到恢复并再次响应.
在崩溃-恢复模型中, 节点上持久性存储 (即非易失性存储) 的数据会在崩溃之后得以保存,
而内存中状态可能会丢失.

拜占庭 (任意) 失效模型

节点可能发生任何事情, 包括试图作弊和欺骗其他节点.
对于真实系统的建模, 最普遍的组合是 崩溃-恢复模型 结合 部分同步模型.
```

## 一致性与共识

* **可线性化与可串行化**

```
可线性化 (Linearizability) 非常容易与
可串行化 (Serializability) 发生混淆,
两个词似乎都在表达类似 "可以按顺序排列" 的意思.
但是它们完全不同, 需要仔细区分:

可串行化

可串行化是事务的隔离属性, 其中每个事务可以读写多个对象 (行, 文档, 记录等).
它用来确保事务执行的结果与串行执行 (即每次执行一个事务) 的结果完全相同,
即使串行执行的顺序可能与事务实际执行顺序不同.

可线性化

可线性化是读写寄存器 (单个对象) 的最新值保证. 它并不要求将操作组合到事务中,
因此无法避免写倾斜等问题, 除非采取其他额外措施 (如实现实体化冲突).

数据库可以同时支持可串行化与线性化,
这种组合又被称为严格的可串行化或者强的单副本可串行化
(strong one copy serializability, strong-1SR)
基于两阶段加锁或者实际以串行执行都是典型的可线性化.

但是, 可串行化的快照隔离则不是线性化的:
按照设计, 它可以从一致性快照中读取, 以避免读写之间的竞争.
一致性快照的要点在于它里面不包括快照点创建时刻之后的写入数据,
因此从快照读取肯定不满足线性化.
```

* **CAP 理论是否有用?**

```
CAP 有时也代表一致性, 可用性, 分区容错性, 系统只能支持其中两个特性.
不过, 这种理解存在误导性. 网络分区是一种故障, 不管喜欢还是不喜欢,
它都可能发生, 所以无法选择或逃避分区的问题.

在网络正常的时候, 系统可以同时保证一致性 (线性化) 和可用性.
而一旦发生了网络故障, 必须要么选择线性一致性, 要么可用性.
因此, 更准确的称呼应该是 "网络分区情况下, 选择一致还是可用",
高可靠的网络会帮助减少发生的概率, 但无法做到彻底避免.

有必要指出, 在 CAP 的诸多讨论中, 术语可用性存在争议,
其形式化定理中的可用性与通常意义上的理解有些差别.
许多所谓的 "高可用性" (容错) 系统实际上并不符合 CAP 对可用性的特殊定义.
总之, 围绕着 CAP 有太多的误解与困扰, 最后反而无法帮助我们更好地理解系统,
所以本人建议最好避免使用 CAP.

正式定义的 CAP 定理范围很窄, 它只考虑了一种一致性模型 (即线性化)
和一种故障 (网络分区, 节点仍处于活动状态但相互断开), 而没有考虑网络延迟,
节点失败或其他需要折中的情况. 因此, 尽管 CAP 在历史上具有重大的影响力,
但对于一个具体的系统设计来说, 它可能没有太大的实际价值.
```

```
全序和偏序的差异也会体现在不同的数据库一致性模型中

可线性化

在一个可线性化的系统中, 存在全序操作关系.
系统的行为就好像只有一个数据副本, 且每个操作都是原子的,
这意味着对于任何两个操作, 我们总是可以指出哪个操作在先.

因果关系

如果两个操作都没有发生在对方之前, 那么这两个操作是并发关系.
换言之, 如果两个事件是因果关系 (一个发生在另一个之前),
那么这两个事件可以被排序; 而并发的事件则无法排序比较.
这表明因果关系至少可以定义为偏序, 而非全序.
```

* **共识的不可能性**

```
或许你可能听说过 FLP 结论, 其字母源于三位作者 Fischer, Lynch 和 Paterson.
FLP 表明如果节点存在可能崩溃的风险, 则不存在总是能够达成共识的稳定算法.
在分布式系统中, 我们必须假设节点可能会崩溃,
我们在讨论如何达成共识, 而这里又说可靠的共识无法实现. 到底怎么回事呢?

答案是 FLP 结论是基于异步系统模型而做的证明, 这是一个非常受限的模型,
它假定确定性算法都不能使用任何时钟或超时机制.
如果算法可以使用超时或其他方法来检测崩溃节点 (即使怀疑可能是误报)
那么可以实现稳定的共识方案. 另外,
即使算法使用了随机数来检测节点故障也可以绕过 FLP 结论.
因此, FLP 结论有其重要的理论意义, 但对于实际的分布式系统通常达成共识是可行的.
```

```
在这个描述中, 共识算法必须满足以下性质

协商一致性 (Uniform agreement)
  所有的节点都接受相同的决议.
诚实性 (Integrity)
  所有节点不能反悔, 即对一项提议不能有两次决定
合法性 (Validity)
  如果决定了值 v, 则 v 一定是由某个节点所提议的.
可终止性 (Termination)
  节点如果不崩溃则最终一定可以达成决议.
```

```
此外, 共识算法往往对网络间问题特别敏感.
例如, Raft 已被发现存在不合理的边界条件处理:
如果整个网络中存在某一条网络连接持续不可算,
Raft 会进入一种奇怪的状态:
它不断在两个节点之间反复切换主节点, 当前主节点不断被赶下台,
这最终导致系统根本无法安心提供服务. 其他共识算法也有类似的问题,
所以面对不可靠网络, 如何设计更具鲁棒性的共识算法仍然是一个开放性的研究问题.
```

## 批处理系统

* 以 UNIX 哲学作类比, 蛮有意思的

```
曾经:
  Online service -> 即时性的 服务 单个用户
  Batch          -> 延迟的 批量 处理多个用户
现在:
  Online service
  Streaming/批流一体

拭目以待!
```

* Bulk Synchronous Parallel (BSP) model

```
这个特点使得基于日志的消息系统更像上一章的批处理过程,
其中派生数据通过可重复的转换过程与输入数据明确分离.
它支持更多的实验性尝试, 也更容易从错误和故障中进行恢复,
从而成为集成数据流的不错选择.
```

```
事件溯源的哲学是小心的 区分事件和命令.
当来自用户的请求第一次到达时,
它最初是一个命令: 此时它可能仍然会失败,
例如因为违反了某些完整性条件.
应用程序必须首先验证它是否可以 执行该命令,
如果验证成功并且命令被接受,
它将变成一个持久且不可变的事件.
```

```
如果你擅长数学, 你可能会说应用状态是事件流对时间的积分得到的,
而变化流是状态对时间的求导得到的.
虽然这个比喻有一定的局限性
(例如状态的二阶导数似乎没有意义),
但可以帮助进一步认知数据.
```

```
事务日志记录了对数据库所做的所有更改.
高速追加是更改日志的唯一方法.
从这个角度来看, 数据库的内容保存了日志中最新记录值的缓存.
日志是事实.
数据库是日志子集的缓存,
该缓存子集恰好是来自日志的每个记录和索引值的最新值.
```

## 流处理系统

```
一个可用的复杂系统总是从可用的简单系统演进而来,
反过来这话也是正确的:
从零开始设计的复杂系统从来都用不了, 也没办法把它变成可用.
      - John Gal <系统学> (1975)
```

## 数据系统的未来

> 看看数年前的书预判未来的技术路线, 别有一番意境
