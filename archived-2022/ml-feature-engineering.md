---
title: 特征工程的艺术 - 通用技巧与实用案例
description: 雁来音信无凭, 路遥归梦难成. 离恨恰如春草, 更行更远还生.
date: 2022-05-26
---

- [特征工程的艺术: 通用技巧与实用案例](https://www.ituring.com.cn/book/2817)
  - [特征工程的艺术](https://book.douban.com/subject/35902261/)

```
对于回归问题, 误差可以用差来测量, 但这样负的误差会和正的误差抵消,
所以有必要取误差的绝对值. 不过, 绝对值不是连续可导的,
所以我们通常使用误差的平方, 即均方误差 (MSE).
为了让度量与原始信号有同样的单位, 你可以求出均方误差的平方根, 得到 RMSE.
还有一些不太常用的误差度量方式, 例如,
你可以不使用平方, 转而使用另一种指数, 或者使用负的误差代替正的误差.

请注意, 如果直接使用误差作为 ML 算法 (例如, 训练一个神经网络) 优化过程的一部分,
那么连续可导的要求就是非常重要的. 你还可以在执行算法时使用一种度量,
在评价结果时使用另一种度量, 并看一下它们是否与基本目的 (效用度量) 相符合.

最后, 上面讨论的度量方式都使用均值, 都试图总结出模型行为最有代表性的方面,
但无法体现结果中的方差 (variance). 这个话题在 ML 中已经得到了非常深人的研究,
就是偏差 (bias: 学习了错误的事情; 由于模型局限性而产生的误差)
与方差 (variance: 学习了分散的点; 由于有限的数据抽样以及不同样本生成的不同模型而产生的误差)
的均衡问题.
```

```
识别异常值要比删除它们更重要, 因为如果数据中有很多异常值,
就表示这可能是一种非正态的"肥尾"分布.
你收到的异常值还可能是一种削波数据或失真数据
(即所谓的删失数据, censored data).

你可以在异常值上训练一个独立模型, 因为它们有时候会表现出一种所谓的王者效应
(king effect), 即分布中的前几个代表与其余实例在行为上截然不同.

对于 FE, 我们可以使用异常值检测在训练数据上学习一个模型,
再使用这个模型找出不正常的实例及其特征值. 一般来说,
异常值检测技术可以是监督的, 也可以是无监督的. 在 FE 中,
花费额外精力来标注异常值是不太可行的, 所以我们重点关注无监督技术.
主要的技术包括聚类, 密度估计和单类别 SVM. 在进行无监督异常值检测时,
可以使用诊断技术和调节技术:
诊断技术用于找出异常值,
调节技术用来使 ML 模型在存在异常值时具有稳健性.
```

- __使用典型值进行替换__.
  - 如果你没有某个值的任何有关信息, 那么当这个值缺失时,
    就不应该用一个能被 ML 算法选择出来作为强烈信号的值来填充它.
  - 对于这种缺失数据, 你可以让 ML 算法尽可能地忽略这个特征.
  - 要完成这个任务, 应该用均值 (如果具有多个异常值, 就使用中位数)
    或最常见的值 (众数) 来替换它, 使其尽量平淡无奇.
  - 这种方法尽管非常简单, 但仍然远远好于让这个值为 `0`,
    就像很多 ML 工具箱中那样.
  - 同样, 如果数据中有很多自然产生的 `0`, 你应该仔细地研究一下,
    看看这些 `0` 能否构成一个独立的现象.
  - 例如, 添加一个表示这个值是否为 `0` 的指示特征.

- __仿射变换__ 是一种线性变换,
  是通过将源平面上的三个点映射到目标平面上的三个点来定义的.
  - 从数学上说, 它的定义方式是乘以一个 `2 × 2` 矩阵再加上一个 `2 × 1` 向量.
  - 它包括平移, 缩放和旋转, 这些是我们要使用的一个仿射变换子集.

- 如果不考虑特征的可解释性, 就可以使用最新的技术从核变换生成一些随机特征.
  特别地, 从对核函数的傅里叶分解中随机选择正弦波是对该函数一个有效,
  基于特征的近似.
- 核方法的基础是一项重大理论成果, 称为 __Mercer__ 定理,
  即对于任意定义了对象间一种度量方式 (对称且半正定) 的函数 `K`,
  都存在一个 `φ`, 使得 `K` 可以用 `φ` 的内积来表示.
- 相关文献提出了多种核, 包括`线性核`, `多项式核`, `Fisher 核`,
  `径向基函数 (RBF) 核`, `图核`, `字符串核`等, 它们的应用非常广泛.

---

- 如果你在处理一个距离对于模型非常重要的问题,
  就可以考虑选择一些特殊元素计算距离, 得到距离的上下文,
  从而将领域知识加入问题中.
