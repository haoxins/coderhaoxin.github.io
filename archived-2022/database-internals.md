---
title: 数据库系统内幕
description: 少焉, 月出于东山之上, 徘徊于斗牛之间. 白露横江, 水光接天.
date: 2022-03-11
---

* [数据库系统内幕](https://book.douban.com/subject/35078474/)
  - 作为**微信读书**付费会员, 为微信读书的`时效性`提升点赞
  - 个人觉得本书优于
    [数据密集型应用系统设计](https://book.douban.com/subject/30329536/)
  - 偏: 综述

---

## 存储引擎简介

* **空间局部性**原则是**局部性原则**之一. 该原则指出,
  如果访问一处存储, 则其附近的其他存储区域也会在不久的将来被访问.

* 认为`行存储`和`列存储`之间的区别仅在于数据的存储方式有所不同, 这是不充分的.
  选择数据布局只是列式存储所针对的一系列可能的优化的步骤之一.
  - 在一次读取中, 从同一列中读取多个值可以显著提高缓存利用率和计算效率.
    在现代 `CPU` 上, 向量化指令可以使单条 `CPU` 指令一次处理多个数据点.
  - 另外, 将具有相同数据类型的值存储在一起可以提高压缩率.
    我们可以根据不同的数据类型使用不同的压缩算法,
    并为每种情况选择最有效的压缩方法.

* 面向列的数据库不应与宽列式存储 (如 `BigTable` 或 `HBase`) 相混淆.
  在这些数据库中, 数据表示为多维映射, 列被分组为列族 (通常存储相同类型的数据),
  并且在每个列族中, 数据被逐行存储.
  - 此布局最适合存储由一个键或一组键来检索的数据.

* 索引文件的大小通常比数据文件小. 文件被划分成页 (`page`),
  每个页通常具有单个或多个磁盘块的大小.
  - 页可以被组织成记录的序列或分槽页 (`slotted page`).
* 新增记录 (插入) 和对现有记录的更新使用`键/值`对来表示.
  大多数现代存储系统不显式地删除页上的数据.
* 相反, 它们使用删除标记 (`deletion marker`, 也称为墓碑 (`tombstone`)),
  其中包含此删除动作的元数据, 如键和时间戳. 在垃圾收集过程中,
  这些被更新或被删除标记遮盖 (`shadowed`) 过的记录所占用的空间会被数据库回收.
  该过程会读取页, 然后将活动 (即未被遮盖) 的记录写入新位置, 并丢弃被遮盖的记录.

* 主 (数据) 文件上的索引称为主索引. 但是, 在大多数情况下,
  我们还可以假设主索引是在主键或作为主键的一组键之上构建的.
  所有其他索引都称为二级索引 (`secondary index`).
* 二级索引可以直接指向数据记录, 也可以简单地存储它的主键.
  指向数据记录的指针可以保存堆文件或索引组织表中的偏移量.

* 如果数据记录的顺序遵循搜索键顺序, 则这种索引称为聚簇索引
  (`clustered/clustering index`).
  聚簇索引中的数据记录通常与索引存储于同一文件,
  有时也存放在单独的聚簇文件中, 而这些文件均保留了键的顺序.
* 如果数据存储在单独的文件中, 且其顺序不遵循键顺序,
  则索引称为非聚簇索引 (`nonclustered/unclustered index`).

* 索引组织表以索引的顺序保存数据, 因此按定义一定是聚簇的.
  主索引通常是聚簇的, 而根据定义, 二级索引一定不是聚簇的,
  因为它们是用于加速主键以外的键的访问的.
  - 聚簇索引既可以是索引组织的,
    也可以具有单独的索引和数据文件.

* 如果工作负载主要由读操作组成, 那么更新几个索引可能没有什么问题,
  但是对于具有多个索引, 以写为主的工作负载, 这种方法便不能很好地工作了.
* 为了减少指针更新的成本, 一些数据库的具体实现是使用主键进行间接操作,
  而不是直接使用数据偏移量.

* 通常, `LSM`树和`B`树之间的区别便是数据是不可变的还是原地更新的,
  但是也存在受`B`树启发但不可变的数据结构.

## B树基础知识

* 在深入研究`B`树之前, 让我们先讨论一下为什么应该考虑替代传统搜索树
  (例如, 二分搜索树, `2-3`树和`AVL`树).

* 一棵**二分搜索树**中只能有一个根节点.
* 每个节点将搜索空间分为左子树和右子树:
  - 一个节点的键大于其左子树中存储的任何键,
  - 且小于其右子树中存储的任何键.
* 插入操作并不会遵循任何特定模式, 元素插入可能导致树不平衡的情况
  (即它的一个分支比另一个分支长). 最差的情况得到一棵病态树, 更像一个链表,
  此时我们得到的不是期望的对数时间复杂度, 而是线性时间复杂度.

* 平衡树指的是高度为
  $$ \log_2 N $$
  的树 (其中 `N` 是树中数据项的总数),
  并且两个子树之间的高度差不大于 `1`.

* 树的平衡是通过以最小化树高并将每一边的节点数
  保持在界限内的方式重新组织节点来完成的.
* 保持树的平衡的方法之一是在添加或删除节点后执行旋转:
  如果插入操作使分支不平衡 (分支中的两个连续节点只有一个子节点),
  则可以围绕中间节点旋转树.

* 由于扇出较低 (扇出是指每个节点允许拥有的最大子节点数),
  我们必须相当频繁地执行平衡操作, 重新定位节点并更新指针.
  维护成本的增加使得二分搜索树作为存储在磁盘上的数据结构变得不切实际.

* 适合磁盘实现的树必须具有以下属性:
  - 高扇出, 以改善邻近键的数据局部性.
  - 低高度, 以减少遍历期间的寻道次数.

* 典型的 `SSD` 由记忆单元构成, 这些单元连接成串
  (每个串通常为 `32` 到 `64` 个单元),
  串被组合成阵列, 阵列被组合成页, 页被组合成块.
* 可写 (可编程) 或可读的最小单元是页. 但是, 我们只能对空的记忆单元进行更改
  (即, 对写入之前已擦除的单元进行更改).
* 最小的擦除实体不是页, 而是保存多个页的块, 这就是为什么它通常被称为擦除块.
  空块中的页必须按顺序写入.
* 每当我们从块设备读取单个字时, 包含它的整个块将会被读取.
  这是我们不能忽视的一个限制, 在处理基于磁盘存储的数据结构时应该始终考虑到这一点.

* 每当我们从块设备读取单个字时, 包含它的整个块将会被读取.
  这是我们不能忽视的一个限制,
  在处理基于磁盘存储的数据结构时应该始终考虑到这一点.

---

* `B`树是有序的: `B`树节点内的键按顺序存储. 因此,
  我们可以使用像二分搜索这样的算法来定位搜索到的键.
  这也意味着`B`树中的查找具有对数复杂度.
* 使用`B`树, 我们可以有效地执行单点查询和范围查询.
  在大多数查询语言中, 我们通过谓词相等 `(=)`
  表示单点查询来定位单个项, 而通过谓词比较
  `(<, >, ≤ 和 ≥)`
  表示范围查询来按顺序查询多个数据项.

* `B`树由多个节点组成. 每个节点最多可容纳`N`个键和`N+1`个指向子节点的指针.
  这些节点在逻辑上分为三类.
  - **根节点**: 根节点没有父节点, 是树的顶端.
  - **叶节点**: 叶节点是没有子节点的底层节点.
  - **内部节点**: 连接根节点和叶节点的其他节点,
    `B`树通常包含多层的内部节点.

* 由于`B`树是一种页组织技术 (即用于组织和导航固定大小的页的技术),
  所以节点和页这两个术语在描述中可相互替换.
* 节点容量与其实际持有的键的个数之间的关系称为占用率.
* `B`树的特征在于其扇出 (fanout):
  存储在每个节点中的键的个数. 为保持树的平衡需要做出一些结构上的更改,
  而更高的扇出则有助于均摊这些更改的所带来的开销.
* 同时, 通过在单个块或多个连续块中存储指向子节点的键和指针,
  可以减少寻道的次数.

* `B`树允许在根节点, 内部节点和叶节点当中的任意层上储存值.
  而`B+`树则仅在叶节点中存储值, 其内部节点仅存储分隔键,
  用于指引搜索算法去找到叶节点上的关联值.

* `B+`树广为人知, 因此我们像其他文献中一样称之为`B`树.

* 存储在`B`树节点中的键称为索引条目 (`index entry`),
  分隔键 (`separator key`) 或分隔符单元格 (`divider cell`).
* 它将树分割成子树 (也称为分支或子范围), 其持有包含对应键的范围.
  键存储时已经排好序, 以便使用二分搜索.
* 查找算法通过定位一个键并跟随相应的指针从较高的层次移动到较低的层次来找到一个子树.

* 使`B`树与众不同的是, 它不是自上而下构建的 (像二分搜索树那样),
  而是采用相反的构建方式 -- 自下而上. 随着叶节点数量的增加,
  内部节点的数量和树的高度也将增加.
* 由于`B`树在节点内部为将来的插入和更新保留了额外的空间,
  所以树的存储占用率可以低至`50%`, 但通常这个数值要高得多.
  较高的占用率不会对`B`树的性能产生负面影响.

* 更准确地说, 如果以下条件成立, 则需要分裂节点:
  - 对于叶节点: 如果节点最多可以容纳 `N` 个键值对,
    且再插入一个键值对将使其超过其最大容量 `N`.
  - 对于非叶节点: 如果节点最多可以容纳 `N+1` 个指针,
    且再插入一个指针将使其超过其最大容量 `N+1`.
* 分裂是通过分配新节点, 将一半元素从原分裂节点传输给它
  并添加它的第一个键和指向父节点的指针来完成的.
  - 在这种情况下, 我们说这个键被提升 (promote) 了.
    执行分裂处的数组下标称为分裂点 (也称为中点).
  - 分裂点之后的所有元素 (在非叶节点分裂的情况下, 包括分裂点)
    都被传输到新创建的兄弟节点, 其余元素保留在分裂节点中.
  - 如果父节点已满, 即没有容纳被提升的键和指向新创建节点的指针的空间时,
    也必须分裂父节点. 此操作可能会一直递归传播到根节点.

* 分裂完成后有两个节点, 我们必须选择正确的节点才能完成插入.
  为此, 我们可以使用分隔键不变量. 如果插入的键小于要提升的键,
  则最后插入到原分裂节点. 否则, 我们将要插入的键放入新创建的节点.
* 总之, 节点分裂分为四个步骤:
  1. 分配一个新节点.
  2. 将一半元素从分裂节点复制到新节点.
  3. 将新元素放入相应节点.
  4. 在分裂节点的父节点处, 添加一个分隔键和指向新节点的指针.

* 更准确地说, 如果满足以下条件, 则合并两个节点:
  - 对于叶节点: 如果一个节点可以容纳最多 `N` 个键值对,
    并且两个相邻节点中的键值对的数目加起来小于或等于 `N`.
  - 对于非叶节点: 如果一个节点可以容纳最多 `N+1` 个指针,
    并且两个相邻节点中指针的数量加起来小于或等于 `N+1`.

* 总之, 假设元素已经被删除, 节点合并分为三步:
  1. 从右节点复制所有元素到左节点.
  2. 从父节点删除右节点指针 (如果是非叶子节点合并, 则将此指针进行降级).
  3. 删除右节点.
* 为了减少分裂和合并的次数, `B` 树经常采用的技术之一是再平衡.

## 文件格式

* 磁盘数据结构中指针管理的语义与内存中的有所不同,
  你可以将磁盘上的`B`树看作一种页管理机制:
  - 算法需要组合页并在页中移动.
  - 需要计算页和指向它们的指针并将它们放置在相应的位置.

* 大多数的数值类型都用固定大小的值来表示.
  当处理多字节数值时, 务必在编解码时使用相同的**字节序**
  (`byte-order` 或 `endianness`),
  **字节序**决定了一组字节的先后顺序.
  - **大端**: 从最高有效字节 (MSB) 开始,
    从高位到低位依次排列.
    换句话说, 最高有效字节具有最低的地址.
  - **小端**: 从最低有效字节 (LSB) 开始,
    从低位到高位依次排列.

* 通常, 在设计一种文件格式时, 首先要确定寻址方式:
  是否要将文件拆分为相同大小的页,
  哪些页由单个块或多个连续块所组成.
* 大多数原地更新的存储结构都使用相同大小的页,
  从而大大简化了读取和写入访问.
* 仅追加 (append-only) 的存储结构通常也按页写入数据:
  记录被一条一条地追加上去, 一旦内存中该页写满了,
  就将其刷写到磁盘上.
* 文件通常以定长的头部 (header) 开始, 可能以一个定长的尾部
  (trailer) 结束.
  - 尾部包含需要被快速访问的辅助信息或解析文件其余部分所必要的信息.

* 数据库将数据记录存储在数据文件和索引文件中.
  这些文件被划分为固定大小的单元, 称为页.
  - 页大小通常是文件系统块的整数倍, 一般是 `4~16KB`.

* 从数据结构的角度来看, 在`B`树中, 我们区分了叶节点
  (包含键和数据记录对) 与非叶节点 (包含键和指向其他节点的指针).
  - 每个`B`树节点占据一个页或多个链接在一起的页,
    因此在讨论B树时, "节点"和"页" (甚至"块")
    这几个术语经常可以互换使用.

* 空间回收可以通过简单地重写页并移动记录来完成,
  但是需要保证记录的偏移量不变, 因为页外的指针会用到这些偏移量.
  在做到这一点的同时, 我们希望尽可能减少空间浪费.
* 总之, 我们需要一种页格式, 它允许我们:
  - 以最小的开销存储变长记录
  - 回收已删除记录所占用的空间
  - 引用页中的记录, 无论这些记录具体在什么位置

* 我们将页组织成一个槽或单元格 (cell) 的集合,
  并将指针和单元格分别存放在页两侧的独立内存区域中.
  若想保持记录原来的顺序, 我们只需要重新组织指向单元格的指针;
  若要删除一条记录, 我们只需将记录的指针置为空或删除指针即可.
* 分槽页具有一个固定大小的头部, 其中包含关于页和单元格的重要信息.
  单元格的大小可能各不相同, 并且可以容纳任意数据:
  - 键, 指针, 数据记录等.

* **最小开销**: 分槽页唯一的额外开销是一个指针数组,
  用于保存记录实际所在位置的偏移量.
* **空间回收**: 通过对页进行碎片整理和重写, 就可以回收空间.
* **动态布局**: 从页外部, 只能通过槽`ID`来引用槽,
  而确切的位置是由页内部决定的.

* 我们假定单个页内所有单元格是统一的
  - 例如, 要么全是键单元格, 要么全是键值单元格;
  - 类似地, 要么全都包含定长数据, 要么全都包含变长数据,
    但不能是二者的混合.
* 这样一来, 单元格的元数据只要在每个页上保存一份即可,
  而不用让每个单元格都保存一份.

* 从页删除一条记录不用删除实际的单元格,
  也不用移动其他单元格以重用这些释放的空间.
  相反, 可以将这个单元格标记为已删除,
  并根据被释放内存的大小以及指针更新内存中的可用列表.
* 可用列表保存了可用段的偏移量及其大小. 每当插入新单元格时,
  我们首先检查可用性列表, 看看是否有能放得下的段.

* 至于具体要使用哪一个空闲块, 是通过以下策略计算的:
  - **首次适配优先**
  - 这种方法可能会造成较大的额外开销,
    因为当我们把数据填进第一个合适的段之后,
    剩余的空间可能不够放下其他的单元格,
    因而被浪费掉了.
  - **最佳适配优先**
  - 在最佳适配中, 我们尝试寻找一个段,
    使得插入之后段内剩余的空间最小.

* 如果找不到足够长的连续字节来存放新的单元格,
  但有足够多的碎片字节可用, 我们会读出所有存活的单元格再重新写入,
  即对页进行碎片整理, 以回收空间来留给新的写入.
* 如果在碎片整理之后依然没有足够的可用空间, 我们就要创建一个溢出页.

* 非加密哈希和 `CRC` 不应当用于验证数据是否已被篡改.
  对于这类场景, 请务必使用专为安全性设计的强加密哈希.
* `CRC` 的主要目标是确保数据没有非人为的, 意外的变化,
  而非用于抵御攻击或人为的修改.

* 由于计算整个文件的校验和通常是不切实际的,
  而且不太可能每次访问文件都读取全部内容,
  所以校验和通常是针对每个页计算的, 并保存在页头部.
* 这样一来, 校验和可以更健壮 (因为仅针对一小部分数据),
  而且就算单个页发生损坏, 我们也不用丢弃整个文件.

## B树的实现

* 存储同级指针的缺点之一是在分裂和合并期间必须更新它们.
  由于更新必须在同级节点中进行,
  而不是在`分裂/合并`节点中进行,
  所以可能需要额外的锁.

* `B`树分隔键有严格的不变式: 它用于将树拆分为子树并对这些子树进行遍历,
  因此指向子页的指针总是比指向键的指针多一个.
* 在许多实现中: 每个分隔键都有一个子指针, 而最后一个指针则单独存储,
  因为它并没有与任何键相匹配.
* 如果最右侧的子指针被拆分, 并且新的单元格被追加到其父节点上,
  则必须重新分配最右子指针.

* `B`树算法规定每个节点持有特定数量的元素. 由于某些值具有不同的大小,
  所以根据`B`树算法, 可能会出现这样一种情况:
  - 节点尚未满, 但保存该节点固定大小的页上已经没有更多的可用空间了.
  - 调整页大小需要将已经写入的数据复制到新区域, 这通常是不切实际的.
    但我们仍然需要找到一种方法来增加或扩展页大小.
* 为了实现变长节点而无须将数据复制到新的连续区域,
  我们可以从多个链接起来的页中构建节点.
  - 例如, 默认页大小为`4K`, 而在插入几个值之后, 其数据大小增长到`4K`以上.
  - 此时我们并不使用任意大小的页, 而是允许节点以`4K`为增量进行增长,
    因此我们可以分配一个`4K`的扩展页, 并从原始页链接到它.
  - 这些链接起来的页被称为溢出页 (overflow page),
    我们将原始页称为主页 (primary page).

* 二分搜索算法接收一个包含已排序元素的数组和一个搜索键, 并返回一个数字.
  如果返回的数字是整数, 则我们找到了要搜索的键,
  并且数字指定了它在输入数组中的位置.
  而返回值为负数则表示搜索到的键不存在于输入数组中, 并给出了一个插入点.

* 如果节点被分裂或合并, 则可以使用导航信息来为上拉到父节点的键查找插入点,
  并在必要时沿着树向上走, 以将结构更改传播到更高层的节点.
  - 这个栈一般在内存中维护.

* 一些`B`树的实现方案试图推迟分裂和合并操作, 以便通过在层内再平衡各元素来平摊代价,
  或将元素从占用较多的节点转移到占用较少的节点中, 通过这一方式尽可能推迟分裂或合并.
  - 虽然维护代价可能更高一些, 但这有助于提高节点利用率以及减少树的层数.

* 许多数据库系统使用单调自增的数值作为主索引的键. 这为优化创造了机会,
  因为所有的插入都发生在索引的末尾 (在最右边的叶子中),
  所以大多数分裂发生在每层的最右节点上.
* 此外, 由于键是单调递增的, 所以考虑到追加相对更新和删除的比例很低,
  相对于键随机排列的情况而言, 非叶页上的碎片化程度更低.

* 我们可以在不同的粒度级别上进行压缩. 尽管压缩整个文件可以产生更好的压缩率,
  但由于整个文件必须在更新时被重新压缩, 所以它的应用有限.
  - 更细粒度的压缩通常更适合较大的数据集.

## 事务处理与恢复

* 页缓存充当了持久性存储 (磁盘) 和存储引擎其余部分之间的中介.
  它将状态更改暂存在内存中, 同时也用于缓存那些尚未与持久性存储同步的页.
  一切数据库状态的更改都首先被应用在缓存的页上.
* 日志管理器记录了已应用在缓存页上的操作 (日志条目),
  这些操作尚未与持久性存储同步, 而日志可以确保这些操作不会在崩溃时丢失.
  - 换句话说, 在数据库启动期间, 我们利用日志来重新应用这些操作并重建缓存状态.
    日志条目也可以用来撤销已中止的事务所做的更改.

* 假设没有其他进程修改磁盘上的数据, 则内存中的缓存页可以被重用.
  这种做法有时也称为虚拟磁盘. 仅当内存中没有页副本可用时,
  对虚拟磁盘的读取才会访问物理存储.
* 更多时候, 我们称上述机制为页缓存或缓冲池.
  页缓存负责缓存从磁盘读取的页. 如果数据库崩溃或意外关闭,
  则缓存的内容也将丢失.

* 将未缓存的页从磁盘加载进来的过程称为换入 (page in).
  缓存的页一旦被更改过就成了脏页,
  直到这些更改被刷写 (flush) 到磁盘上.

* 页缓存的主要功能可以总结为以下几点:
  - 在内存中保留被缓存的页的内容.
  - 把对磁盘页的修改缓冲起来, 并且修改的是缓存的版本.
  - 当被请求的页不在内存中且可用空间足够时,
    页缓存会将其换入并返回缓存的版本.
  - 如果请求的页在缓存中, 则直接返回缓存的版本.
  - 如果可用空间不足以放下新的页, 则某些其他页会被换出,
    被换出的页的内容会被刷写回磁盘.

* 如果某个页被修改了 (例如追加了一个新的单元格),
  则该页被标记为脏页. 页上的脏标志位表示其内容与磁盘不同步,
  必须将其刷写到磁盘上才能保证持久性.

* 另一个要记住的重要属性是持久性: 如果数据库崩溃,
  则所有未刷写的数据都会丢失. 为了确保所有更改都被持久化,
  检查点进程会协调刷写进程.
* 检查点进程控制预写日志 (WAL) 和页缓存, 并确保两者协同工作.
  只有当缓存页完成刷写之后, 相关操作的日志记录才能从 `WAL` 中丢弃.
  在上述过程完成后才能将脏页换出缓存.

* **LRU** 也按插入顺序维护一个换出候选队列, 但是当我们重复访问某个页时,
  `LRU` 会将其放回队列尾部, 就像首次换入时那样. 然而,
  并发环境下每次访问都要更新引用和重新链接节点可能代价较高.
* 在某些情况下, 效率可能比精度更重要. **CLOCK**
  算法变体常常被用作 `LRU` 的一种更加紧凑, 更加缓存友好且并发性更好的替代品.

* **CLOCK-sweep** 算法将页的引用和与之关联的访问位保存在环形缓冲区中.
  一些变体使用计数器而不是比特位来描述频率.
* 每当访问某个页面时, 都将它的访问位设置为`1`. `CLOCK`
  算法的工作原理是循环检查环形缓冲区上的访问位:
  - 如果访问位为`1`且该页未被引用, 则将其置为`0`并检查下一页.
  - 如果访问位已经为`0`, 则将该页作为一个要换出的候选,
    并安排在后续将其换出.
  - 如果页当前正被引用, 则它的访问位保持不变.
    算法假定被访问页的访问位不可为`0`,
    因此不会被换出缓存, 这使得被引用的页更不可能被置换.

* 使用环状缓冲区的一个优点是:
  - 时钟指针和缓冲区内容都可以用`比较-置换` (**CAS**)
    原子操作来修改, 无须额外的加锁机制.

---

* **预写日志** (Write-Ahead Log, **WAL**, 也称为提交日志)
  是一种仅追加的辅助磁盘数据结构, 用于崩溃和事务的恢复.
  页缓存允许我们在内存中缓冲对页面内容的更改,
  而在将缓存的内容刷写回磁盘之前, `WAL`
  是保留操作历史的唯一磁盘副本.

* 预写日志的主要功能可以概括为:
  - 在允许页缓存将页上的修改缓存起来的同时,
    保证数据库系统仍然具有持久性语义.
  - 在那些受操作影响的缓存页被同步到磁盘上之前,
    将所有操作持久化到磁盘上.
    每个修改数据库状态的操作必须先写日志到磁盘上,
    然后才能修改相关页的内容.
  - 当发生崩溃时, 使系统可以从操作日志中重建内存中丢失的更改.
* 除此以外, 预写日志在事务处理中也起着重要的作用.
  它确保将数据存储到持久性存储中, 即使发生崩溃也依然可用:
  - 通过重放日志便可以恢复未提交的数据,
    这样数据库就可以完全恢复到崩溃前的状态.

* 由于 `WAL` 是一个不可变的, 仅追加的数据结构,
  所以读取方可以安全地访问写入边界之前的内容,
  同时写入方可以继续将数据追加到日志尾部.
* `WAL` 由日志记录组成, 每条记录都有一个唯一的,
  单调递增的日志序列号 (LSN). 通常, `LSN`
  由一个内部的计数器或时间戳表示.
* 由于日志记录不一定占据整个磁盘块, 所以其内容会被缓存在日志缓冲区中,
  并在强制刷盘 (force) 操作时被刷写到磁盘上.
  强制刷盘操作发生在日志缓冲区被填满时,
  也可能被来自事务管理器或页缓存的请求所触发.
  各日志记录必须以 `LSN` 的顺序刷写到磁盘上.
* 除了单独的操作记录外, `WAL` 还会保存事务完成的记录.
  只有当事务提交记录完成刷盘之后, 才能将该事务视为已提交.
* 系统在回滚或恢复期间也有可能发生崩溃, 为了确保这种情况下系统能继续正常工作,
  某些系统会在撤销操作时记录补偿日志记录 (`CLR`) 并将其存储在日志中.

* 物理日志记录了前像和后像, 受操作影响的整个页都要被记录下来.
  逻辑日志记录了要对页应用哪些操作, 例如"向键Y插入数据记录X",
  以及相应的撤销操作, 例如"删除与Y关联的值".
* 在实践中, 许多数据库结合使用上述两种方法:
  - 使用逻辑日志记录执行撤销操作 (以提升并发),
  - 使用物理日志记录执行重做操作 (以缩短恢复时间).

* `ARIES` 是一种 `steal/no-force` 的恢复算法.
  它使用物理重做日志来提高恢复期间的性能 (因为能更快地应用更改),
  并使用逻辑撤销日志来提高正常操作期间的并发
  (因为逻辑撤销操作可以独立地应用到页中).
  - 它使用 `WAL` 来实现在恢复时重放历史, 从而完整地重建数据库状态
    (未提交事务的修改已被撤销), 并在撤销期间构建补偿日志记录.

---

* 当数据库崩溃后重启时, 恢复过程分为三个阶段:
  - 分析阶段识别出页缓存中的脏页以及崩溃时正在进行的事务.
    脏页的信息用于标识重做阶段的起点.
    进行中事务的清单用于在撤销阶段中回滚未完成的事务.
  - 重做阶段重放历史记录直到崩溃点, 并将数据库恢复到先前的状态.
    此阶段会处理未完成的事务以及那些已提交但尚未将修改刷写到持久化存储的事务.
  - 撤销阶段回滚所有未完成的事务, 并将数据库还原到最后的一致状态.
    所有操作均按反向时间顺序回滚. 为了防止数据库在恢复过程中再次崩溃,
    撤销事务所做的操作也会被记录到日志中, 以避免重复应用.

* `ARIES` 使用 `LSN` 来识别日志记录,
  通过脏页表来追踪运行中事务修改过的页,
  并使用物理重做, 逻辑撤销和模糊检查点.

---

* 事务管理器和锁管理器协同工作以处理并发控制.
  并发控制是一组用于处理并发事务间交互的技术.
  这些技术可以大致分为以下几类:
  - **乐观并发控制**
  - 乐观并发控制 (`OCC`) 允许多个事务执行并发的读取和写入操作,
    最后确定其执行结果能否被串行化 (serializable).
  - 换句话说, 事务不会彼此阻塞, 而是保留其操作历史,
    并在提交前检查这些历史操作是否存在冲突的可能.
    如果会产生冲突, 则中止其中某一个冲突的事务.
  - **多版本并发控制**
  - 多版本并发控制 (`MVCC`) 允许一条记录同时存在多个时间戳的版本,
    通过这种方式保证事务读到的是数据库过去某个时刻的一致视图.
  - `MVCC` 可以使用验证技术来实现, 即只允许多个更新或事务提交中的某一个获胜,
    也可以使用无锁技术 (例如时间戳排序) 或基于锁的技术 (例如两阶段锁).
  - **悲观并发控制**
  - 悲观 (也称为保守) 并发控制 (`PCC`) 既有基于锁的实现,
    也有不加锁的实现, 它们的主要区别在于如何管理和授权对共享资源的访问.
  - 基于锁的实现要求事务维护数据库记录上的锁,
    以防止其他事务修改被加锁的记录或访问当前事务正在修改的记录,
    直到锁被释放为止.
  - 不加锁的实现根据未完成事务的调度, 维护读取与写入的操作列表以限制事务的执行.
    *悲观的调度可能导致死锁*: 多个事务需要互相等待对方释放锁才能继续执行.

* **事务**包括对数据库状态的一系列读取和写入操作以及业务逻辑 (应用于读取内容上的转换).
* **调度** (schedule) 是指数据库视角上执行一组事务所需的操作列表
  (即仅包含与数据库状态交互的操作, 例如读, 写, 提交和中止),
  因为我们假定其他所有的操作都没有副作用 (换句话说, 不影响数据库状态).
* 如果一个调度中包含其中每个事务的所有操作, 则称它是**完整的**.
* 一个正确的调度在逻辑上等效于原始操作列表, 但是可以并行执行其中某些部分,
  也可以出于优化目的对其进行重新排列, 只要不违反
  `ACID` 性质并保证各事务的结果正确即可.

* 如果一个调度中的事务完全独立且无交错地执行, 则我们称它为串行的调度:
  - 每个事务在下一个事务开始之前已完全执行.
    相比于多个事务的各种交错执行, 串行执行很容易进行论证.
  - 但是, 总是一个接一个地执行事务将会大大限制系统吞吐量并损害性能.
* 我们需要找到一种方法, 它能够并发执行事务操作, 同时保持串行调度的正确性和简单性.
  **可串行化**的调度可以满足这一要求.
  - 如果一个调度等效于同一组事务的某一完整串行调度,
    则该调度是可串行化的.
  - 换句话说, 它产生的结果与我们以某种顺序一个接一个地执行一组事务的结果相同.

---

* 在执行并发事务期间可能发生的读异常:
 - **脏读**
 - **不可重复读**
 - **幻读**

* **脏读** (dirty read) 是指一个事务能读到其他事务未提交的更改.
* **不可重复读** (nonrepeatable read),
  是指同一事务两次查询同一行却得到不同的结果.
  - 有时也称为模糊读 (fuzzy read)
* 如果我们在事务执行过程中使用范围读取
  (即不是读取单个数据记录, 而是读取一个范围内的记录), 则可能会看到幻记录.
  - **幻读**是指事务两次查询同样的行集合却得到不同的结果.
  - 它与*不可重复读*类似, 但仅适用于**范围查询**.

* 同样地, 也存在具有类似语义的写异常:
  - **丢失更新**
  - **脏写**
  - **写偏斜**

* **丢失更新** (lost update) 发生在事务 `T1` 和 `T2` 同时尝试更新 `V` 的值时.
* **脏写** (dirty write) 指的是某个事务拿到了一个未提交的值 (即脏读),
  对其进行修改并保存.
  - 换句话说, 事务结果来自从未提交过的值.
* **写偏斜** (write skew) 是指各个单独的事务都遵守要求的约束,
  但它们的组合却违反了这些约束.

* 最低 (换句话说, 最弱) 的隔离级别是**读未提交** (read uncommitted).
  - 在此隔离级别下, 事务系统允许一个事务观察到其他并发事务的未提交更改.
  - 也就是说, **脏读**是允许的.
* 如果两次读取之间存在已提交的修改, 则同一事务中的两次查询会得到不同的结果.
  换句话说, 脏读是不允许的, 但**幻读**和**不可重复读**是允许的.
  该隔离级别称为**读已提交** (read commited).
* 如果我们进一步禁止不可重复读, 则会得到**可重复读**
  (repeatable read) 的隔离级别.
* 最强的隔离级别是**可串行化** (serializability).

* 不同于**可线性化**, **可串行化**是指按任意顺序执行多个操作,
  它并不暗示或强制某一特定的事务执行顺序.
  - `ACID` 中的**隔离性**意味着**可串行化**.
* 然而, 实现可串行化需要协调, 换句话说,
  并发执行的事务必须进行协调以确保遵守约束,
  并在发生冲突时强加某一串行顺序.

---

* **乐观并发控制**假设事务冲突很少发生, 并且不同于加锁阻塞事务执行的方式,
  我们可以通过在事务提交前验证事务来防止并发事务间发生读或写冲突, 确保可串行化.
  一般来说, 事务执行分为三个阶段:
  - **读阶段**
  - 事务在其私有上下文中执行各步骤, 此时一切更改都对其他事务不可见.
    在该步骤完成后, 我们就知道了事务的所有依赖条件 (读集合),
    以及事务会产生的所有副作用 (写集合).
  - **验证阶段**
  - 检查并发事务的读集合和写集合, 查看其操作之间是否存在可能违反可序列化性质的冲突.
    如果事务读取的某些数据现在已过期,
    或者事务的写入将覆盖在其读阶段提交的事务所写入的某些值,
    则清除事务的私有上下文, 重启读阶段.
  - 换句话说, 验证阶段确定提交事务是否遵守 `ACID` 性质.
  - **写阶段**
  - 如果验证阶段未发现任何冲突, 则事务可以将其写集合从私有上下文提交到数据库状态中.

* 验证有两种实现方式: 检查与已提交事务的冲突 (**后向式**),
  以及检查与当前处于验证阶段的事务的冲突 (**前向式**).
  - 不同事务的验证阶段和写阶段应当原子地完成.
    在验证其他事务时, 不允许提交任何事务.
  - 由于验证阶段和写阶段通常比读阶段短, 因此这是可以接受的妥协.
* **后向式**并发控制确保任意一对事务 `T1` 和 `T2` 都具有以下性质:
  - 如果 `T1` 在 `T2` 的读阶段开始之前提交, 则 `T2` 可以提交.
  - 如果 `T1` 在 `T2` 的写阶段之前提交, 则 `T1` 的写集合与 `T2` 的读集合不相交.
    换句话说, `T1` 不能写入任何 `T2` 看到的值.
  - 如果 `T1` 的读阶段在 `T2` 的读阶段之前完成
    (注: 但不满足上一条的情况, 即在 `T2` 进行写阶段时 `T1` 还未提交.),
    则 `T2` 的写集合与 `T1` 的读或写集合均不相交.
    换句话说, 两个事务操作独立的数据集合, 因此两者都可以提交.

---

* **多版本并发控制**是数据库中实现事务一致性的一种方法, 它允许记录存在多个版本,
  并使用单调递增的事务 `ID` 或时间戳.
  - 这使得读写操作在存储层面上只需要最小限度的协调,
    因为读操作可以继续访问旧的值, 直到新的值被提交.
* `MVCC` 区分已提交和未提交的版本, 对应于已提交和未提交事务的值的版本.
  最后提交的值的版本也就是值的当前版本. 一般在 `MVCC` 中,
  事务管理器的目标是确保任一时刻最多只有一个未提交的值版本.
* 根据数据库实现的隔离级别, 读操作也许能访问或不能访问未提交的值.
  多版本并发可以用加锁, 调度和冲突解决技术 (例如两阶段锁) 来实现,
  也可以用时间戳排序来实现. 实现快照隔离是 `MVCC` 的一大使用场景.

* **悲观并发控制**方案比乐观方案更保守.
  这种方案在事务运行时确定其间的冲突并阻塞或中止执行.
* 时间戳排序是最简单的悲观 (无锁) 并发控制方案之一,
  其中每个事务都有一个时间戳,
  事务操作能否执行取决于是否已经提交过时间戳更晚的事务.
* 为了实现这一点, 事务管理器需要维护每个值的
  `max_read_timestamp` 和 `max_write_timestamp`,
  它们分别描述了并发事务执行的读和写操作.
* 如果读操作的时间戳小于读到的值的 `max_write_timestamp`,
  则会导致当前事务中止. 因为已经有一个较新的值存在,
  若允许该操作则会违反事务顺序.
* 类似地, 时间戳小于 `max_read_timestamp` 的写操作将与最近的读操作冲突.
  但是这种情况是被允许的, 因为我们可以安全地忽略过期的写入值.
* 这个猜想通常被称为托马斯写规则. 每当进行读或写操作时,
  相应的最大时间戳都会被更新. 中止的事务会以新的时间戳重新开始,
  否则新的事务必定会被再次终止.

---

* 基于**锁**的并发控制方案是**悲观**并发控制的一种形式,
  它对数据库对象显式地加锁, 而不是用时间戳排序之类的协议来制定操作的顺序.
  - 使用锁的缺点包括锁竞争和扩展性问题.
* 使用最广泛的基于锁的技术之一是**两阶段锁** (**2PL**),
  它将锁管理分为两个阶段:
  - **增长**阶段 (也称为扩张阶段), 此阶段将获取事务所需的所有锁, 并且不释放任何锁.
  - **收缩**阶段, 此阶段释放增长阶段获得的所有锁.
* 由上述两个定义可以推断出一条规则:
  - 事务一旦释放了哪怕一个锁, 就不能再获取任何锁.
  - 值得注意的是, `2PL` 并不阻止事务在这两个阶段中执行事务步骤,
    但是某些 `2PL` 变体 (例如 `保守2PL`) 确实增加了这些限制.

* 尽管名称很相似, 但**两阶段锁**和**两阶段提交**是两个完全不同的概念.
  - **两阶段提交**是一种用于分布式多分区事务的协议,
    而两阶段锁是一种并发控制机制, 常用于实现可串行化.

---

* **死锁**
* 在锁协议中, 事务尝试获取数据库对象上的锁, 如果无法立刻获得锁,
  则事务必须等待直到锁被释放. 可能会发生这样的情况:
  - 两个事务都在尝试获取所需的锁以继续执行,
    而最后都在等待对方释放其持有的某个锁.
* 最简单的处理死锁的方法是引入超时机制并中止长时间运行的事务,
  假定它们可能处于死锁状态.
* 另一种策略, 即 `保守2PL`, 要求事务在执行任何操作之前先获取所有锁,
  如果做不到就中止事务. 但是, 这些方法极大地限制了系统的并发,
  因此数据库系统大多使用**事务管理器**来检测或避免 (或者说防止) 死锁.

* 为了避免死锁, 限制锁的获取以确保不会产生死锁,
  事务管理器可以用事务时间戳来确定事务优先级.
  - 较低的时间戳通常意味着较高的优先级, 反之亦然.
* 如果事务 `T1` 尝试获取 `T2` 当前持有的锁,
  并且 `T1` 具有更高的优先级 (它在`T2`前开始),
  那么我们可以使用以下限制之一来避免死锁:
  - **等待-死亡** (wait-die)
  - 允许 `T1` 阻塞以等待锁. 否则 (注: 如果 `T2` 在 `T1` 之前开始.),
    `T1` 将中止并重新启动. 换句话说, 事务只能被时间戳更高的事务阻塞.
  - **伤害-等待** (wound-wait)
  - `T2` 中止并重新启动 (`T1` 伤害 `T2`). 否则 (如果 `T2` 在 `T1` 之前开始),
    则允许 `T1` 等待. 换句话说, 事务只能被时间戳更低的事务阻塞.
  - 事务处理需要一个调度器来处理死锁. 同时,
    **闩锁**依靠程序员来保证不会发生死锁, 而不依赖于死锁避免机制.

* **锁**
* 在事务处理过程中, 保护逻辑和物理数据完整性的机制有所不同.
  负责逻辑和物理完整性的两个概念分别是**锁** (lock) 和**闩锁** (latch).
* 其在命名上有点令人迷惑, 因为这里说的闩锁在系统编程中通常称为锁,
  但在本节中我们将阐明它们的区别和含义.
* 锁用于隔离和调度重叠的事务, 管理数据库内容 (而非内部存储结构),
  并且锁是在键上获取的. 锁可以保护某个特定的键 (无论该键存不存在)
  或一个范围内的键.
* 锁通常在树实现之外进行存储和管理, 它表示一个较高层级的概念,
  由数据库的锁管理器管理.
* **锁比闩锁更重量级**, 且在事务执行期间一直持有.
* **闩锁**
* 另一方面, 闩锁用于保护物理表示: 在插入, 更新和删除操作期间,
  叶子页的内容会被修改; 在叶子页发生下溢或上溢时,
  页的分裂与合并向上传播, 非叶子页的内容以及树结构也会被修改.
* 在这些操作期间, 闩锁保护了树的物理表示 (页内容及树结构),
  并且它是在页的级别上获取的. 在访问任何页前必须先加闩锁,
  以确保并发安全. **无锁并发控制技术也必须使用闩锁**.

---

* **读写锁**
* 最简单的闩锁实现将会授予请求线程排他性的读写访问权限.
  但是, 大多数时候, 我们不需要把所有进程相互隔离.
  - 例如, 并发地读取页不会有什么问题, 因此,
    我们只要确保并发的写操作不重叠, 以及读操作与写操作不重叠.
  - 为了达到这种粒度级别, 我们可以使用**读写锁** (又称为 **RW锁**).
* 读写锁允许多个读操作同时访问该对象, 而只有写操作 (通常相对较少)
  必须获得对该对象的排他性访问.
* 读写锁的兼容性表:
  - 只有读操作 (`读读`) 可以共享锁所有权,
    而读写操作的其他组合 (`读写`, `写写`) 都要获得排他性所有权.

## B树的变体

* **写时复制B树**, 其结构类似于`B`树, 但其中的节点是不可变的,
  并且不会原地更新. 相反, 页被复制, 更新并写入新的位置.
* **惰性B树**, 通过缓冲对节点的更新减少来自后续相同节点写操作的
  `I/O` 请求数量.
  - 我们还将介绍`双组件LSM树`, 它扩展了缓冲以实现完全不可变的`B`树.
* **FD树**则采用不同的缓冲方法, 有点类似于`LSM`树.
  - `FD`树在一个小型`B`树中缓冲更新. 一旦这个树被填满,
    它的内容就会被写入一个不可变的运行实例中.
  - 更新以级联的方式在不可变运行实例的层之间传播, 从较高的层传播到较低的层.
* **Bw树**将`B`树节点分成几个较小的部分, 以仅追加的方式进行写入.
  - 它通过批处理不同节点上发生的更新, 减少了少量但频繁的写操作的成本.
* **缓存无关B树** (cache-oblivious B-Tree) 则允许以
  类似于内存中数据结构的构建方式处理磁盘上的数据结构.

---

* 有些数据库并不构建复杂的锁机制, 而是使用写时复制 (copy-on-write)
  技术来保证并发操作时的数据完整性. 在这种情况下, 每当页即将被修改时,
  就会先复制其内容, 然后修改复制的页而不是原来的页.
  - 这样便创建出了一个平行的树状层次结构.
* 旧版本的树对于与写入者并发的读取者而言仍然是可访问的,
  而访问修改后的页的写入者必须等待之前的写操作完成.
  在创建新的页层次结构之后, 指向最顶层页的指针将被自动更新.
* 由于必须复制整个页的内容, 所以这种方法的一个明显的缺点是它需要更多的空间
  (即使旧版本只会保留很短的时间: 在使用旧页的并发操作完成之后, 那些页可以被立即回收)
  和处理器时间.
  - 由于`B`树通常是较浅的, 所以这种方法的简洁性和优势往往仍然大于其缺点.
* 这种方法最大的优点是读取者不需要同步. 因为已写入的页是不可变的,
  可以在不需要额外加锁的情况下被访问. 因为写操作是针对复制页进行的,
  所以读取者不会阻塞写入者. 任何操作都不会得到一个处于不完整状态的页.
  即使是系统崩溃也不会使页处于损坏状态,
  因为只有当所有页的修改都完成时, 最顶端的指针才会切换.

---

* 让我们来看看如何使用缓冲实现**惰性B树**. 为此,
  我们可以在`B`树节点被换入后立即在内存中物化它们,
  并使用该结构存储更新, 直到我们准备好刷写它们.
* `MongoDB` 现在默认的存储引擎 `WiredTiger` 也使用了类似的方法.
  它的行存储`B`树的实现针对内存和磁盘页使用了不同的格式.
  - 在持久化内存页之前, 它们必须经过一个协调的过程.
* 在读取过程中会访问更新缓冲区: 其内容将与原始磁盘页中的内容进行合并,
  以返回最新的数据. 当刷写页时, 更新缓冲区内容将与页内容协调然后保存在磁盘上,
  以覆盖原始页. 如果协调后页的大小大于最大值, 则将其拆分为多个页.
  - 更新缓冲区使用跳表 (skiplist) 来实现,
    跳表具有类似于搜索树的复杂度, 但具有更好的并发性.

* 在原地更新的`B`树的实现中, **写放大**是最显著的问题之一:
  对一个`B`树页后续的更新可能需要在每次更新时更新其磁盘驻留页副本.
* 第二个问题是**空间放大**: 我们保留了额外的空间以实现更新.
  这也意味着, 为了传输承载着所请求数据的每个有用字节,
  我们不得不额外传输一些空字节以及页的其余部分.
* 第三个问题是解决**并发问题**和处理闩锁的复杂性.
* 为了同时解决这三个问题, 我们必须采取一种与目前已经讨论过的方法完全不同的方法.
  缓冲更新有助于减轻写放大和空间放大问题, 但不能解决并发问题.

---

* 我们可以通过使用仅追加存储来对不同节点进行批量更新, 将节点链接成链,
  并使用内存数据结构, 该结构允许通过单个`CAS`操作在节点之间建立指针,
  从而使树无锁. 这种方法称为 `Buzzword` 树 (**Bw树**).
* `Bw`树区分基节点的写入与修改. 修改 (增量节点) 形成一个链:
  一个从最新修改到旧修改的链表, 该链表末尾则是基节点 (base node).
  每个更新都可以单独存储, 而不需要重写磁盘上的现有节点.
  增量节点 (delta node) 可以表示插入,
  (与插入无法区分的) 更新或删除.
* 由于基节点和增量节点的大小不太可能是页对齐的, 所以将它们连续存储是有意义的,
  而且由于在更新期间基节点和增量节点都不会被修改
  (所有修改只是将一个节点插入现有链表头部), 所以我们不需要预留任何额外的空间.
* 将节点作为逻辑实体而不是物理实体是一种有趣的范式转变:
  - 我们不需要预先分配空间, 不需要节点具有固定的大小,
    甚至不需要将它们保持在连续的内存段中.
* 这当然有一个缺点: 在读取过程中, 必须遍历所有增量并将其应用到基节点上,
  以重建实际的节点状态. 这有点类似于`LA`树所做的事情:
  - 更新与主结构分开存放, 并在读取时重放.
* 维护一个允许将数据项插到子节点之前的磁盘树状结构的成本相当高:
  它要求我们不断地更新父节点指向最新增量的指针.
  这就是为什么由增量节点和基节点链接在一起而组成的`Bw`树节点具有逻辑标识符,
  并使用一个从标识符到其在磁盘上位置的内存映射表.
* 使用这种映射还帮助我们摆脱闩锁: `Bw`树不是在写入时获取独占所有权,
  而是对映射表中的物理偏移量使用`CAS`原子操作.

* 要更新一个`Bw`树节点, 该算法执行以下步骤:
  - 1) 通过从根到叶遍历树来定位目标逻辑叶节点.
    映射表包含了到更新链中的目标基节点或最新增量节点的虚拟链接.
  - 2) 使用指向在步骤`1`中定位的基节点 (或指向最新的增量节点)
    的指针来创建一个新的增量节点.
  - 3) 用指向步骤`2`期间创建的新增量节点的指针来更新映射表.
  - 4) 步骤`3`中的更新操作可以使用`CAS`这个原子操作来完成,
    因此与指针更新并发的所有读取都被安排在写入之前或之后,
    读取者或写入者都不会被阻塞. 在此之前的读取是沿着旧指针进行的,
    看不到新的增量节点, 因为它尚未被放置.
    而在此之后的读取则是沿着新指针进行的, 可以观察到更新.
    如果两个线程试图将一个新的增量节点放置到同一个逻辑节点,
    那么只有其中一个线程可以成功, 而另一个线程必须重试该操作.

* `Bw`树是一个有趣的`B`树变体, 其在如下几个重要方面进行了改进:
  - **写放大**, 非阻塞访问和缓存友好性.
  - 实验性的存储引擎`Sled`实现了它的一个修改版本.
  - 而`CMU`数据库组开发了`Bw`树的一个内存版本,
    称为`OpenBw`树, 并发布了一个实用的实现指南.

## 日志结构存储

* 不可变 **LSM**树 (Log-Structured Merge Tree) 使用仅追加存储和合并协调,
  而`B`树则在磁盘上定位数据记录并在文件中的原始偏移量上更新页.
* 原地更新存储结构针对读取进行了性能优化: 当在磁盘上定位数据之后,
  就可以将记录返回客户端. 这是以牺牲写入性能为代价的:
  - 要在原地更新数据记录, 首先必须在磁盘上进行定位.
* 另一方面, 仅追加存储是对写入性能进行的优化.
  写操作不必在磁盘上找到记录来覆盖它们. 然而, 这是以读取性能为代价的,
  读取必须检索多个数据记录版本并对它们进行协调.

* `LSM`树是类似于`B`树的磁盘驻留结构的变体, 其中节点完全被填满,
  并为顺序磁盘访问进行了优化. 尽管`LSM`树通常被用作`B`树的一种替代,
  但`B`树通常被用作`LSM`树的不可变文件的内部索引结构.
* `LSM`树在写远大于读的应用程序中特别有用. 考虑到数据量和采集速率在不断增长,
  在现代数据密集型系统中这种情况是常见的.
* `B`树和`LSM`树都需要一些内务处理 (housekeeping) 来优化性能,
  但原因不尽相同. 由于分配文件的数量稳定增长, 所以`LSM`树必须合并和重写文件,
  以确保在读取过程中访问尽可能少的文件, 因为请求的数据记录可能分布在多个文件中.
* 另一方面, 可变文件可能必须被部分或全部重写,
  以减少碎片并回收被更新或删除的记录所占用的空间.
  - 当然, 内务处理的确切工作很大程度上取决于具体实现.

* `LSM`树由较小的内存驻留组件和较大的磁盘驻留组件组成.
  要在磁盘上写出不可变的文件内容, 首先需要在内存中对其进行缓冲和排序.
* 内存驻留组件 (通常称为 `memtable`) 是可变的: 它缓冲数据记录,
  并充当读写操作的目标. 当其大小达到一个可配阈值时,
  `memtable`中的内容将会被持久化到磁盘上.
* `memtable`的更新不需要磁盘访问, 也没有相关的`I/O`开销.
  需要一个单独的预写日志文件以保证数据记录的持久性.
  在向客户端确认操作之前, 数据记录会被追加到日志中并提交到内存.
* 缓冲是在内存中完成的: 所有读写操作都应用于一个内存驻留表,
  该表维护一个允许并发访问的有序数据结构, 其通常是某种形式的内存排序树,
  或任何可以提供类似性能和特征的数据结构.
* 磁盘驻留组件则是通过将内存中缓冲的内容刷写到磁盘来构建的.
  磁盘驻留组件仅用于读取: 缓存的内容被持久化成文件,
  而这些文件永远不会被修改.
* 这允许我们从简单操作的角度来考虑: 对内存中的表进行写操作,
  以及对磁盘和基于内存的表进行读, 合并和文件删除操作.
* 在`LSM`树中, 插入, 更新和删除操作不需要在磁盘上定位数据记录.
  但是, 在读取的过程中需要对冗余的记录进行协调.

---

* 由于磁盘驻留表上的内容是经过排序的, 所以我们可以使用多路归并排序算法.
  例如, 我们有三个数据源: 两个磁盘驻留表和一个`memtable`.
  - 通常, 存储引擎提供游标或迭代器来遍历文件内容.
    此游标保存上次消耗的数据记录的偏移量,
    可以用来检查迭代是否完成, 也可以用于抽取下一个数据记录.
* 多路归并排序使用一个优先级队列, 如**最小堆** (`min-heap`),
  该队列最多保存`N`个元素 (其中`N`是迭代器的数目),
  该队列对其内容进行排序并准备返回的下一个最小的元素.
  每个迭代器的头被放入队列. 队列头部的元素就是所有迭代器的最小值.

* 合并迭代只是从多个数据源合并数据的一个方面.
  另一个重要方面是与同一键相关联的数据记录的协调和冲突解决.
* 不同的表可能持有相同键的数据记录, 例如更新和删除,
  这时必须对它们的内容进行协调.
  前例中的优先级队列的实现必须能够允许插入与相同键关联的多个值,
  并触发协调.

* 在`LSM`树中, 磁盘驻留表的数量不断增长, 但可以通过触发周期性的压实来减少.
* 压实会挑选多个磁盘驻留表, 使用前面提到的合并和协调算法迭代它们的全部内容,
  并将结果写入新创建的表.

---

* 在压实过程中, 墓碑不会被立即丢弃. 它们会被保留,
  直到存储引擎可以确定在任何其他表中都不存在时间戳更小且键相同的数据记录.
* **RocksDB**保留墓碑直到它们到达最底层. 这是因为数据库的最终一致性,
  这样做可以确保其他节点观察到墓碑. 在压实过程中保留墓碑对于避免数据复活很重要.
* 压实提供了多种优化机会, 并且有许多不同的压实策略.
  其中一种常用的压实策略称为层级压实 (leveled compaction),
  例如**RocksDB**就使用这一策略.

* 层级压实将磁盘驻留表划分为多个层级. 每个层上的表都有目标大小,
  每个层都有相应的序号 (标识符). 有些违反直觉的是, 序号最高的层被称为最底层.

* 在实现最优压实策略时, 我们必须考虑多个因素. 一种方法是回收重复记录占用的空间,
  减少空间开销, 但这会产生由不断重写表导致的更高的写放大.
  替代方案是避免连续重写数据, 而这又增加了读放大
  (在读取期间协调关联到相同键的数据记录的开销)
  和空间放大 (因为冗余记录会被保存更长时间).

---

* 总结起来, 当以不可变的方式在磁盘上存储数据时, 我们面临三个问题:
  - **读放大**
  - 由为了检索数据而需要读取多个表所引起.
  - **写放大**
  - 由压实过程中不断进行的重写所引起.
  - **空间放大**
  - 由存储关联到同一键的多个记录所引起.

* `RUM`猜想指出, 减少其中两项开销将不可避免地导致第三项开销的恶化,
  并且优化只能以牺牲三个参数中的一个为代价.
* 这个开销模型并不完美, 因为它没有考虑其他重要的指标, 如
  延迟, 访问模式, 实现复杂度, 维护成本以及与硬件相关的细节.
  对于分布式数据库很重要的概念, 如一致性含义和复制开销,
  也没有被考虑进去.
* 然而, 该模型可以被用作初步评估或当作一种经验法则,
  它有助于我们理解存储引擎必须提供什么.

* 磁盘驻留表通常使用有序字符串表 (Sorted String Table, `SSTable`) 来实现.
  顾名思义, `SSTable`中的数据记录是按照键顺序进行排序和布局的.
* `SSTable`通常由两个组件组成: 索引文件和数据文件.
  索引文件是用能够以对数时间复杂度 (如B树) 或常量时间复杂度
  (如哈希表) 进行查找的某种结构来实现的.

* `LSM`树中读放大的来源是, 我们必须寻址多个磁盘驻留表, 以便完成读取操作.
  这是因为我们不一定能预先知道一个磁盘驻留表是否包含要搜索的键指向的数据记录.
* 防止表查询的方法之一是在元数据中存储其键的范围 (存储给定表中的最小和最大键),
  并检查要搜索的键是否在该表的范围之内. 这一信息是不精确的,
  它只能告诉我们数据记录是否可能会出现在表中.
* 为了改进这种情况, 包括 Apache Cassandra 和 RocksDB
  在内的许多实现都使用一种称为布隆过滤器 (Bloom Filter) 的数据结构.

---

* **布隆过滤器**是一种空间效率很高的概率型数据结构,
  可以用来测试元素是否是集合的成员. 它可能产生假阳性匹配
  (返回"元素在集合中"的结果, 而实际上该元素却不在集合中),
  但不会出现假阴性匹配
  (若返回"元素不在集合中"的结果, 则保证该元素肯定不是集合的成员).
* 换句话说, 可以使用布隆过滤器来**判断**键是否可能在表中或**肯定不在**表中.

* 在查询期间跳过布隆过滤器返回"不匹配"的文件, 而只访问其余文件,
  以查明数据记录是否确实存在.
* 使用与磁盘驻留表相关联的布隆过滤器能显著减少读取过程中要访问的表的数量.

* 布隆过滤器使用一个大的比特数组和多个哈希函数构建.
  将这些哈希函数应用于表中记录的键, 并将哈希值作为数组下标来将其对应比特位设置为`1`.
* 如果哈希函数所确定的所有比特位都为`1`, 则表示该搜索键在该集合中可能是存在的.
  在查找过程中, 当检查布隆过滤器中的元素是否存在时, 需要再次计算键的哈希函数:
  - 如果所有哈希函数确定的位都为`1`, 则返回肯定的结果,
    说明该项目有一定概率是集合中的成员;
  - 如果至少有一个位为`0`, 则我们可以肯定地说该元素不存在于集合中.
* 应用于不同键的哈希函数可能返回相同的比特位并导致哈希冲突,
  比特位为`1`仅表示某个哈希函数为某个键产生了该比特位上的一个置位.
* 假阳性的概率是通过配置比特集的大小和哈希函数的数量来控制的:
  - 在较大的比特集中, 冲突的概率较小;
  - 同样, 若拥有更多的哈希函数, 则我们也可以检查更多的比特位,
    这也将产生一个更精确的结果.

* 较大的比特集占用较多的内存,
  而用较多的哈希函数计算结果又可能会对性能产生负面影响,
  因此我们必须在可接受的概率和产生的开销之间进行权衡.

---

* 随着固态硬盘变得更经济, 日志结构存储 (Log-Structured Storage, LSS)
  系统开始流行. `LSM`树和固态硬盘是一个很好的搭配,
  因为序列化的工作负载和仅追加写入有助于减少原地更新带来的放大,
  而原地更新会对固态硬盘的性能产生负面影响.

* 总结起来, 在固态硬盘上使用日志结构存储的动机是
  将小的随机写入缓冲在一起进行批处理以摊销`I/O`成本,
  这通常会减少操作的数量, 进而减少触发垃圾收集的次数.

## 分布式系统简介

* 除了分布式系统中的**时钟同步**非常困难之外, 当前时间也在不断变化:
  你可以从操作系统请求当前的`POSIX`时间戳,
  并在执行几个步骤后请求另一个当前时间戳, 两次结果是不同的.
  - 尽管这是一个明显的现象,
    但是了解时间的来源以及时间戳捕获的确切时刻至关重要.

* `FLP`不可能问题 (`FLP`是作者姓氏的首字母), 论文讨论了一种共识形式:
  - 各进程启动时有一个初始值, 并尝试就新值达成共识.
  - 算法完成后, 所有正常进程上的新值必须相同.
* 如果网络完全可靠, 很容易对特定值达成共识. 但实际上,
  系统容易出现各式各样的故障, 例如:
  消息丢失, 重复, 网络分区, 以及进程缓慢或崩溃.
* 共识协议描述了这样一个系统: 给定初始状态的多个进程,
  它将所有进程带入决定状态.
* 一个正确的共识协议必须具备以下三个属性:
  - **一致性**
  - 协议达成的决定必须是一致的: 每个进程都做出了决定且所有进程决定的值是相同的.
    否则我们就尚未达成共识.
  - **有效性**
  - 达成共识的值必须由某一个参与者提出, 这意味着系统本身不能"提出"值.
    这也意味着这个值不是无关紧要 (trivial) 的:
  - 进程不能总是决定某个预定义的默认值.
  - **终止性**
  - 只有当所有进程都达到决定状态时, 协议才算完成.

* 文献假定处理过程是完全异步的, 进程之间没有共享的时间概念.
  这样的系统中的算法不能基于超时,
  并且一个进程无法确定另一个进程是崩溃了还是仅仅运行太慢.
* 论文表明, 在这些假设下, 不存在任何协议能保证在有限时间内达成共识.
  - 完全异步的共识算法甚至无法容忍一个远程进程无通知地突然崩溃.
* 如果我们不给进程完成算法步骤设定一个时间上限, 那么就无法可靠地检测出进程故障,
  也不存在确定性的共识算法.
* 但是, `FLP`不可能定理并不意味着我们要收拾东西回家
  (由于达成共识是不可能的).
  - 它仅仅意味着我们不能总是在有限的时间内在一个异步系统中达成共识.
  - 实践中, 系统至少会表现出一定程度的**同步性**,
    而要想解决共识问题还需要一个更完善的模型.

* 从`FLP`不可能定理中可以看出**时序假设**是分布式系统的关键特征之一.
  在异步系统中, 我们不知道进程运行的相对速度,
  也不能保证在有限时间内或以特定顺序传递消息.
  进程可能要花无限长的时间来响应, 而且无法总是可靠地检测到进程故障.
* 对异步系统的主要批评在于上述假设不切实际:
  进程不可能具有任意不同的处理速度, 链路传递消息的时间也不会无限长.
  依赖时间能够简化推理, 并提供时间上限的保证.

* 在异步模型中不一定能解决共识问题. 而且, 不一定能设计出高效的异步算法.
  对于某些任务, 切实可行的解决方案很可能需要依赖时间.

---

* 我们可以放宽一些假设, 认为系统是同步的. 为此我们引入了时间的概念.
  在同步模型下对系统进行推理要容易得多. 它假定各进程的处理速度相近,
  传输延迟是有限的, 并且消息传递不会花任意长的时间.
* **同步系统也可以表示为同步的进程本地时钟**:
  **两个进程本地时间源之间的时间差存在上限**.
* 在同步模型中设计系统可以使用**超时机制**. 我们可以构建更复杂的抽象,
  例如领导者选举, 共识, 故障检测以及基于它们的其他抽象.
  - 这使得最佳情况的场景更加健壮,
    但是如果时序假设不成立则可能导致故障.

* 异步和同步模型的性质可以组合使用, 我们可以将系统视为部分同步的.
  部分同步的系统具有同步系统的某些属性, 但是
  消息传递, 时钟漂移和相对处理速度的边界范围可能并不精确,
  并且仅在大多数时候成立.
* **同步是分布式系统的基本属性**: 它对性能, 扩展性和一般可解性有影响,
  并且有许多对系统正常工作来说是必要的因素.
  - 本书中讨论的一些算法就工作在同步系统的假设下.

## 故障检测

* 我们可以通过算法的效率来判断其优劣: 故障检测器识别进程故障的速度有多快.
  另一种方法是观察算法的准确性: 是否精确地检测到了进程故障.
* 换句话说, 如果一个算法错误地认为一个活着的进程发生了故障或者
  不能检测出实际已发生的故障, 那么它就是不准确的.
* 我们可以把效率和准确度之间的关系看作是一个可调参数:
  一个更高效的算法可能更不准确, 而一个更准确的算法通常更不高效.
  建立既准确又高效的故障检测器被证明是不可能的.

* 许多分布式系统使用心跳 (heartbeat) 来实现故障检测器.
  由于其简单性和很强的完备性, 这种方法非常普遍.
  - 我们在这里讨论的算法假设不存在拜占庭式故障:
  - 进程不会试图故意谎报它们自己及相邻进程的状态.

## 领导者选举

* 尽管领导者选举和分布式锁 (即对共享资源的独占所有权)
  从理论角度看可能很相似, 但它们略有不同.
  如果一个进程因为执行临界区而持有锁, 那么对于其他进程来说,
  知道现在到底是谁持有锁并不重要, 只要满足活动性
  (即锁最终将被释放并允许其他人获得它) 就可以了.
* 相比之下, 选出的进程具有一些特殊性质, 必须让所有其他参与者都知道,
  因此新当选的领导者必须将其角色通知所有对等进程.

## 复制和一致性

* 然而, 由于原子地更新数据的多个副本是一个等同于共识的问题,
  因此数据库中的每个操作都执行共识操作可能成本相当高.
* 我们可以探索一些性价比更高且更灵活的方法,
  允许参与者之间存在某种程度的差异,
  但使数据从用户的角度看起来是一致的.

* 在谈论复制时, 我们最关心这三种事件:
  - `写入`, `副本更新`和`读取`.
* 这些操作触发了由客户端发起的一系列事件. 在某些情况下,
  从客户端角度看, 更新副本可能发生在写操作完成之后,
  但这仍然不能改变这样一个事实:
  - 客户端必须能够以特定的顺序观察到发生过的操作.

* 我们希望在容忍网络分区的同时实现一致性和可用性.
  网络可能被分裂为几个部分, 在这些部分之间, 进程不能相互通信:
  - 被分隔的节点之间发送的一些消息将无法到达目的地.
* 可用性要求任何无故障的节点交付结果, 而一致性要求结果是可线性化的.
* CAP 猜想讨论了一致性 (consistency), 可用性 (availablity)
  和分区容忍性 (partition tolerance) 之间的权衡.

* 构建系统时, 我们可以在提供尽力而为 (best effort)
  可用性的同时保证强一致性, 或者在提供尽力而为一致性的同时保证可用性.
* 在这里, 尽力而为意味着:
  - 如果一切正常, 系统将不会故意违反任何保证,
  - 但是在网络分区的情况下, 允许系统削弱和违反保证.
* 换句话说, CAP 描述了一系列潜在的可选项, 而在这些选项的两端是以下两种系统:
  - 一致性和分区容忍系统 (`CP` 系统)
  - `CP` 系统更倾向拒绝请求, 而不是提供可能不一致的数据.
  - 可用性和分区容忍系统 (`AP` 系统)
  - `AP` 系统放松了一致性要求, 允许在请求期间提供可能不一致的值.

* **PACELC** 猜想是 CAP 的一个扩展, 它指出在网络分区 (P)
  存在的情况下, 可用性和一致性 (AC) 之间存在一个选择.
  - 否则 (Else, E), 即使在没有网络分区的情况下系统运行正常,
  - 我们仍然要在延迟 (Latency, L) 和一致性 (C) 之间做出选择.

* **CAP** 猜想只是一条**经验法则**, 并不一定能说明全部事实.

* CAP 猜想仅以它们最强的形式讨论一致性和可用性:
  - 可线性化和系统最终响应每一个请求的能力.
* 这迫使我们在这两个属性之间做出艰难的权衡. 然而,
  有些应用程序可以从稍微放松的假设中获益,
  我们可以用它们较弱的形式来思考这些属性.
* 系统不一定非得在一致或可用中二选一, 也可以提供更宽松的保证.
  我们可以定义两个可调度量:
  - 收成 (harvest) 和产量 (yield),
  - 在两者之间进行选择仍然可以形成正确的行为:
  - **收成**
  - 收成定义查询的完成程度: 如果查询必须返回`100`行,
    但由于某些节点不可用而只能获取`99`行,
    这仍然比查询完全失败而不返回任何内容要好.
  - **产量**
  - 产量指成功完成的请求数与尝试请求总数之比.
    产量与正常运行时间 (uptime) 不同,
    例如一个繁忙的节点没有宕机,
    但仍然可能无法响应某些请求.
* 这就把权衡的重点从绝对条件变成了相对条件.
  我们可以用收成换取产量, 并允许某些请求返回不完整的数据.
  提高产量的一个方法是只从可用的分区返回查询结果.

## 反熵和传播

## 分布式事务

## 共识
